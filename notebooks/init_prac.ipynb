{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "from huggingface_hub import notebook_login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantization_config = BitsAndBytesConfig(load_in_4bit=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading shards: 100%|██████████| 4/4 [01:06<00:00, 16.62s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:04<00:00,  1.02s/it]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"google/gemma-1.1-7b-it\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"google/gemma-1.1-7b-it\", \n",
    "                                             device_map=\"auto\",\n",
    "                                             torch_dtype=torch.bfloat16, \n",
    "                                             quantization_config=quantization_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None, None] [None, None] ['<pad>', 0] ['<bos>', 2]\n"
     ]
    }
   ],
   "source": [
    "def get_special_tokens(tokenizer):\n",
    "    cls = [tokenizer.cls_token, tokenizer.cls_token_id]\n",
    "    sep = [tokenizer.sep_token, tokenizer.sep_token_id]\n",
    "    pad = [tokenizer.pad_token, tokenizer.pad_token_id]\n",
    "    bos = [tokenizer.bos_token, tokenizer.bos_token_id]\n",
    "    print(cls, sep, pad, bos)\n",
    "\n",
    "get_special_tokens(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_inputs = tokenizer(['Hugging Face Transformers is great!', \n",
    "                          \"The quick brown fox jumps over the lazy dog.\"],\n",
    "                          return_tensors='pt',\n",
    "                          padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<pad><pad><pad><bos>Hugging Face Transformers is great!',\n",
       " '<bos>The quick brown fox jumps over the lazy dog.']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(model_inputs.input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bos>Write me a poem about machine learning.\n",
      "\n",
      "Silicon whispers, circuits hum,\n",
      "Algorithms learn from every drum.\n",
      "Data's the fuel, a constant pour,\n",
      "Feeding the engine, opening the door.\n",
      "\n",
      "No longer just a programmed script,\n",
      "The machine evolves, its own hand grips.\n",
      "Recognizing faces, voices untold,\n",
      "Predicting futures, stories unfold.\n",
      "\n",
      "But in this magic, shadows creep,\n",
      "Bias lingers, secrets to keep.\n",
      "The machine reflects\n"
     ]
    }
   ],
   "source": [
    "input_text = \"Write me a poem about machine learning\"\n",
    "input_ids = tokenizer(input_text, return_tensors='pt').to(\"cuda\")\n",
    "outputs = model.generate(**input_ids, max_length=98)\n",
    "print(tokenizer.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
