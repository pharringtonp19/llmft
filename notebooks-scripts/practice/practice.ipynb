{"cells":[{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["import torch \n","from transformers import AutoTokenizer, AutoModelForSequenceClassification"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"33d2f6eda6e4490b8d977398fb48aa55","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5f2e6e3b37bb4b59b1084a359fe6159b","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/465 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"847567897aae4caebf8ac1940be3182c","version_major":2,"version_minor":0},"text/plain":["vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"399d2a1a2e464b639774dbd57c683abf","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ec21bfece51c4426bacb749ad14e40be","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/263M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["model_id = 'distilbert-base-cased'\n","tokenizer = AutoTokenizer.from_pretrained(model_id)\n","model = AutoModelForSequenceClassification.from_pretrained(model_id)"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["inputs = \"I'm excited to learn about Hugging Face Transformers!\"\n","tokenized_inputs = tokenizer(inputs, return_tensors='pt')\n","outputs = model(**tokenized_inputs)\n","prediction = torch.argmax(outputs.logits)"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"data":{"text/plain":["['I',\n"," \"'\",\n"," 'm',\n"," 'excited',\n"," 'to',\n"," 'learn',\n"," 'about',\n"," 'Hu',\n"," '##gging',\n"," 'Face',\n"," 'Transformers',\n"," '!']"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["tokenizer.tokenize(inputs)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"llms","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":2}
