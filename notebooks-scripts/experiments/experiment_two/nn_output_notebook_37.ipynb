{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6304c977",
   "metadata": {
    "papermill": {
     "duration": 0.007252,
     "end_time": "2024-07-11T20:34:45.114465",
     "exception": false,
     "start_time": "2024-07-11T20:34:45.107213",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### **Import Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "543a734d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-11T20:34:45.128657Z",
     "iopub.status.busy": "2024-07-11T20:34:45.128067Z"
    },
    "papermill": {
     "duration": 0.564073,
     "end_time": "2024-07-11T20:34:45.684778",
     "exception": false,
     "start_time": "2024-07-11T20:34:45.120705",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x7fb996482da0>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/llmft/llms/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "KeyboardInterrupt: \n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset, DatasetDict\n",
    "from tqdm import tqdm\n",
    "import numpy as np \n",
    "import random \n",
    "import math\n",
    "from itertools import chain\n",
    "from IPython.display import display, Markdown\n",
    "import textwrap\n",
    "import tiktoken\n",
    "import csv\n",
    "import time \n",
    "import pandas as pd \n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import transformers\n",
    "from transformers import DataCollatorWithPadding\n",
    "from llmft.train import EncoderTrainer, EarlyStopping\n",
    "from llmft.metrics import compute_recall\n",
    "from llmft.losses import FocalLoss\n",
    "from llmft.utils import predict\n",
    "import seaborn as sns \n",
    "import jax \n",
    "import jax.numpy as jnp \n",
    "import optax \n",
    "from rfp import MLP, Model, ModelParams\n",
    "from rfp.utils import batch_matrix_with_padding\n",
    "from rfp.losses import binary_cross_entropy, Supervised_Loss, mse\n",
    "from rfp.train import Trainer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f193282f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### **Parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c69774c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "seed = 3\n",
    "noise = False \n",
    "verbose = False \n",
    "sample_size = 3_000\n",
    "test_size = 0.3\n",
    "version = 8 \n",
    "lr = 1e-3\n",
    "epochs = 10_000\n",
    "nodes = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1443f346",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "noise = False\n",
    "seed = 2745\n",
    "version = 8\n",
    "sample_size = 5000\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "54a6e852",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### **Seed**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec79dab4",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.random.seed(seed)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7b2790e1",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### **Set Up Paths**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352eb16f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_csv = f'./../../../toy-data/exp2/data_{version}.csv'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cf0330ab",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### **Set Up Plotting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9e9012",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "rcParams['image.interpolation'] = 'nearest'\n",
    "rcParams['image.cmap'] = 'viridis'\n",
    "rcParams['axes.grid'] = False\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "plt.style.use('seaborn-v0_8-dark-palette')\n",
    "\n",
    "from matplotlib import font_manager \n",
    "locations = './../../../styles/Newsreader'\n",
    "font_files = font_manager.findSystemFonts(fontpaths=locations)\n",
    "print(locations)\n",
    "print(font_files[0])\n",
    "for f in font_files: \n",
    "    font_manager.fontManager.addfont(f)\n",
    "plt.rcParams[\"font.family\"] = \"Newsreader\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b1490dc0",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### **First Stage Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa97471",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fstage(var0, var1, var2, var3, var4):\n",
    "    return 0.24*(var3 < 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ccbab8",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read in Data Set\n",
    "df = pd.read_csv(data_csv)\n",
    "\n",
    "# Subsample Observations\n",
    "indices = np.random.choice(df.index, size=sample_size, replace=False)\n",
    "df = df.loc[indices].reset_index(drop=True)\n",
    "\n",
    "# Apply First Stage Function\n",
    "df['FStage_Value'] = df.apply(lambda row: fstage(row['Var0'],\n",
    "                                                 row['Var1'], \n",
    "                                                 row['Var2'], \n",
    "                                                 row['Var3'], \n",
    "                                                 row['Var4']), axis=1)\n",
    "\n",
    "# If Noise: Shuffle the first stage values\n",
    "if noise: \n",
    "    df['FStage_Value'] = df['FStage_Value'].sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Sample Instrumental Values  \n",
    "df['Instrument'] = np.random.binomial(n=1, p=0.5, size=sample_size)\n",
    "\n",
    "# Sample Treatment Values\n",
    "df['Treatment'] = np.random.binomial(n=1, p= df['FStage_Value'] * df['Instrument'], size=sample_size)\n",
    "\n",
    "# Sample Outcome Values\n",
    "df['Outcome'] =  1. + (1. +  2.*(df['FStage_Value'] > 0.))*df['Treatment'] + np.random.normal(size=sample_size)\n",
    "df = pd.get_dummies(df, columns=['Var0', 'Var1', 'Var3', 'Var4'], drop_first=True)\n",
    "df.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "10f9a2ad",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### **Plot Treatment Distribution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e6c75a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(dpi=300, tight_layout=True, figsize=(7, 4.5))\n",
    "ax = plt.axes(facecolor=(.95, .96, .97))\n",
    "\n",
    "# Plot customizations\n",
    "for key in 'left', 'right', 'top':\n",
    "    ax.spines[key].set_visible(False)\n",
    "ax.text(0., 1.02, s='Count', transform=ax.transAxes, size=14)\n",
    "ax.yaxis.set_tick_params(length=0)\n",
    "ax.yaxis.grid(True, color='white', linewidth=2)\n",
    "ax.set_axisbelow(True)\n",
    "plt.hist(df['FStage_Value'], color='#36454F')\n",
    "plt.xlim(0, 1)\n",
    "plt.xlabel('Probability of Treatment Given Instrument', size=14)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8e7174c3",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### **Treatment Fraction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d631f19",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.groupby('Instrument')['Treatment'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0346e012",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f1576196",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### **Preprocess Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfc4972",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Select columns that start with 'Var'\n",
    "var_columns = ['Var2', 'Var0_1', 'Var0_2', 'Var0_3', 'Var0_4', 'Var0_5', 'Var0_6',\n",
    "       'Var0_7', 'Var0_8', 'Var0_9', 'Var0_10', 'Var1_1', 'Var1_2', 'Var1_3',\n",
    "       'Var3_1', 'Var3_2', 'Var3_3', 'Var3_4', 'Var3_5', 'Var3_6', 'Var3_7',\n",
    "       'Var4_1']\n",
    "\n",
    "\n",
    "# Create a numpy matrix from the selected columns\n",
    "X = df[var_columns].to_numpy().astype(float)\n",
    "\n",
    "# Extract the first column\n",
    "first_column = X[:, 0]\n",
    "\n",
    "# Z-score normalization\n",
    "mean_value = np.mean(first_column)\n",
    "std_value = np.std(first_column)\n",
    "normalized_column = (first_column - mean_value) / std_value\n",
    "\n",
    "\n",
    "# Feature Matrix\n",
    "X_normalized = X.copy()\n",
    "X_normalized[:,0] = normalized_column\n",
    "print(f\"Feature shape: \\t\\t{X.shape}\")\n",
    "print(f\"Feature shape: \\t\\t{X_normalized.shape}\")\n",
    "\n",
    "D = jnp.array(df['Treatment'].values.reshape(-1,1)).astype(float)\n",
    "Z = jnp.array(df['Instrument'].values.reshape(-1,1)).astype(float)\n",
    "inputs = jnp.hstack((X_normalized, Z))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2ee7a3b1",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### **Model Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d15d9a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "features = inputs.shape[1] ; print(f\"Number of Features: {features}\")\n",
    "mlp = MLP([nodes, nodes], jax.nn.relu)\n",
    "final_activation_fn = jax.nn.sigmoid \n",
    "model = Model(mlp, final_activation_fn)\n",
    "supervised_loss = Supervised_Loss(binary_cross_entropy, model.embellished_fwd_pass)\n",
    "yuri = Trainer(supervised_loss, optax.sgd(learning_rate=lr, momentum=0.9), epochs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bde8c1ac",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### **Train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63dc3898",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize random key\n",
    "key = jax.random.PRNGKey(seed)\n",
    "\n",
    "# Create keys\n",
    "key, subkey1, subkey2, subkey3, subkey4 = jax.random.split(key, 5)\n",
    "\n",
    "# Initialize parameters\n",
    "params = ModelParams.init_fn(subkey1, mlp, features)\n",
    "\n",
    "# Split Train and Validation Data\n",
    "# Shuffle the indices\n",
    "idx = jax.random.permutation(subkey2, inputs.shape[0])\n",
    "\n",
    "# Determine the indices for training and validation sets\n",
    "train_size = int((1 - test_size) * inputs.shape[0])\n",
    "train_indices = idx[:train_size]\n",
    "val_indices = idx[train_size:]\n",
    "\n",
    "# Create boolean masks for training and validation sets\n",
    "is_in_train = jnp.isin(jnp.arange(inputs.shape[0]), train_indices)\n",
    "is_in_val = jnp.isin(jnp.arange(inputs.shape[0]), val_indices)\n",
    "\n",
    "# Train the model\n",
    "params, opt_params, train_loss_history, val_loss_history = yuri.train_with_val(params, inputs, D, jnp.ones_like(D), is_in_train, is_in_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306809bb",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f9332d98",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### **Plot Losses**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12be91f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot(train_loss_history, label='Training')\n",
    "plt.plot(val_loss_history, label='Validation')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "403e5c26",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### **Estimate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d1f72d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "Dhat = np.array(model.fwd_pass(opt_params, inputs))\n",
    "Dhat1 = np.array(model.fwd_pass(opt_params, jnp.hstack((X_normalized, jnp.ones_like(Z)))))\n",
    "Dhat0 = np.array(model.fwd_pass(opt_params, jnp.hstack((X_normalized, jnp.zeros_like(Z)))))\n",
    "residuals = Dhat - (0.5*Dhat1 + 0.5*Dhat0)\n",
    "est = jnp.linalg.lstsq(jnp.hstack((residuals.reshape(-1,1), jnp.ones_like(residuals.reshape(-1,1)))), jnp.array(df['Outcome'].values.reshape(-1,1)))[0][0]\n",
    "df_result = pd.DataFrame({'Estimate': est})\n",
    "print(est)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "eea2b93c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### **Scatter Comps**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b97737b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "v = (df['FStage_Value']).values\n",
    "plt.scatter(v, Dhat1.reshape(-1,))\n",
    "plt.plot([0,1], [0,1])\n",
    "plt.xlim(0,1)\n",
    "plt.ylim(0,1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e6b2754f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### **Quantile Plot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa4ffe7",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "qs = np.linspace(0, 1, 100)\n",
    "ys1 = np.quantile(Dhat1, qs)\n",
    "ys2 = np.quantile(df['FStage_Value'].values, qs)\n",
    "plt.plot(qs, ys1)\n",
    "plt.plot(qs, ys2)\n",
    "plt.ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9d9c8b8c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### **Save Results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0352b73",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the path for the CSV file\n",
    "file_path = f'./../../../toy-data/exp2/results/nn_{version}_{sample_size}_{noise}.csv'\n",
    "\n",
    "# Check if the file already exists\n",
    "if not os.path.exists(file_path):\n",
    "    # If the file does not exist, write with headers\n",
    "    df_result[['Estimate']].to_csv(file_path, mode='w', header=True, index=False)\n",
    "else:\n",
    "    # If the file exists, append without headers\n",
    "    df_result[['Estimate']].to_csv(file_path, mode='a', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2affc63",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3.918906,
   "end_time": "2024-07-11T20:34:48.307934",
   "environment_variables": {},
   "exception": null,
   "input_path": "./nn_single_run.ipynb",
   "output_path": "nn_output_notebook_37.ipynb",
   "parameters": {
    "noise": false,
    "sample_size": 5000,
    "seed": 2745,
    "version": 8
   },
   "start_time": "2024-07-11T20:34:44.389028",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}