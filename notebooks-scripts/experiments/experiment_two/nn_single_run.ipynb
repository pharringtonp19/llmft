{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Import Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset, DatasetDict\n",
    "from tqdm import tqdm\n",
    "import numpy as np \n",
    "import random \n",
    "import math\n",
    "from itertools import chain\n",
    "from IPython.display import display, Markdown\n",
    "import textwrap\n",
    "import tiktoken\n",
    "import csv\n",
    "import time \n",
    "import pandas as pd \n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import transformers\n",
    "from transformers import DataCollatorWithPadding\n",
    "from llmft.train import EncoderTrainer, EarlyStopping\n",
    "from llmft.metrics import compute_recall\n",
    "from llmft.losses import FocalLoss\n",
    "from llmft.utils import predict\n",
    "import seaborn as sns \n",
    "import jax \n",
    "import jax.numpy as jnp \n",
    "import optax \n",
    "from rfp import MLP, Model, ModelParams\n",
    "from rfp.utils import batch_matrix_with_padding\n",
    "from rfp.losses import binary_cross_entropy, Supervised_Loss, mse\n",
    "from rfp.train import Trainer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "seed = 1 \n",
    "verbose = False \n",
    "sample_size = 3000\n",
    "test_size = 0.25\n",
    "version = 1 \n",
    "lr = 1e-3\n",
    "epochs = 10_000\n",
    "nodes = 64"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Seed**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Set Up Paths**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_csv = f'./../../../toy-data/exp2/data_{version}.csv'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Set Up Plotting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "rcParams['image.interpolation'] = 'nearest'\n",
    "rcParams['image.cmap'] = 'viridis'\n",
    "rcParams['axes.grid'] = False\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "plt.style.use('seaborn-v0_8-dark-palette')\n",
    "\n",
    "from matplotlib import font_manager \n",
    "locations = './../../../styles/Newsreader'\n",
    "font_files = font_manager.findSystemFonts(fontpaths=locations)\n",
    "print(locations)\n",
    "print(font_files[0])\n",
    "for f in font_files: \n",
    "    font_manager.fontManager.addfont(f)\n",
    "plt.rcParams[\"font.family\"] = \"Newsreader\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **First Stage Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions_not_covered = [\n",
    "    \"Short-term illnesses\",\n",
    "    \"Temporary exhaustion\",\n",
    "    \"Behavioral Traits and Conditions\",\n",
    "    \"Having a quick temper without any underlying medical condition\",\n",
    "    \"Certain Addictions\",\n",
    "    \"Substance abuse disorders\",\n",
    "    \"good health\"\n",
    "]\n",
    "\n",
    "conditions_covered = [\n",
    "    \"Mobility impairments\",\n",
    "    \"Visual impairments\",\n",
    "    \"Hearing impairments\",\n",
    "    \"Chronic illnesses\",\n",
    "    \"Respiratory disorders\",\n",
    "    \"Cardiovascular conditions\",\n",
    "    \"Intellectual disabilities\",\n",
    "    \"Learning disabilities\",\n",
    "    \"Autism spectrum disorders\",\n",
    "    \"Psychiatric disorders\",\n",
    "    \"Traumatic brain injuries\",\n",
    "    \"Alzheimer's disease and other dementias\"\n",
    "]\n",
    "\n",
    "disabilities = conditions_covered + conditions_not_covered\n",
    "\n",
    "# Create a list of (0,1)s\n",
    "severity_indicator = [1 if disability in conditions_covered else 0 for disability in disabilities]\n",
    "\n",
    "def fstage(var1, var2, var3, var4, var5, var6, var7, var8, var9):\n",
    "    return 0.02 + 0.35*severity_indicator[var5] + 0.35*var9"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Read in Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_csv)\n",
    "print(df.shape)\n",
    "df.drop_duplicates(inplace=True)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in Data Set\n",
    "df = pd.read_csv(data_csv)\n",
    "print(df.shape)\n",
    "\n",
    "# Subsample Observations\n",
    "indices = np.random.choice(df.index, size=sample_size, replace=False)\n",
    "df = df.loc[indices].reset_index(drop=True)\n",
    "\n",
    "# Apply First Stage Function\n",
    "df['FStage_Value'] = df.apply(lambda row: fstage(\n",
    "                                                 row['Var1'], \n",
    "                                                 row['Var2'], \n",
    "                                                 row['Var3'], \n",
    "                                                 row['Var4'], \n",
    "                                                 row['Var5'],\n",
    "                                                 row['Var6'],\n",
    "                                                 row['Var7'],\n",
    "                                                 row['Var8'],\n",
    "                                                 row['Var9']), axis=1)\n",
    "\n",
    "# Sample Instrumental Values  \n",
    "df['Instrument'] = np.random.binomial(n=1, p=0.5, size=sample_size)\n",
    "\n",
    "# Sample Treatment Values\n",
    "df['Treatment'] = np.random.binomial(n=1, p= df['FStage_Value'] * df['Instrument'], size=sample_size)\n",
    "\n",
    "# Sample Outcome Values\n",
    "df['Outcome'] =  (1. +  2.*(df['FStage_Value'] > 0.))*df['Treatment'] + 0.1*np.random.normal(size=sample_size)\n",
    "\n",
    "df = pd.get_dummies(df, columns=['Var1', 'Var2', 'Var3', 'Var5', 'Var6', 'Var7', 'Var8', 'Var9'], drop_first=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Plot Treatment Distribution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(dpi=300, tight_layout=True, figsize=(7, 4.5))\n",
    "ax = plt.axes(facecolor=(.95, .96, .97))\n",
    "\n",
    "# Plot customizations\n",
    "for key in 'left', 'right', 'top':\n",
    "    ax.spines[key].set_visible(False)\n",
    "ax.text(0., 1.02, s='Count', transform=ax.transAxes, size=14)\n",
    "ax.yaxis.set_tick_params(length=0)\n",
    "ax.yaxis.grid(True, color='white', linewidth=2)\n",
    "ax.set_axisbelow(True)\n",
    "plt.hist(df['FStage_Value'], color='#36454F')\n",
    "plt.xlim(0, 1)\n",
    "plt.xlabel('Probability of Treatment Given Instrument', size=14)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Treatment Fraction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('Instrument')['Treatment'].mean()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Preprocess Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select columns that start with 'Var'\n",
    "var_columns = [col for col in df.columns if col.startswith('Var')]\n",
    "\n",
    "# Create a numpy matrix from the selected columns\n",
    "X = df[var_columns].to_numpy().astype(float)\n",
    "\n",
    "# Feature Matrix\n",
    "X_normalized = jnp.hstack((jax.nn.standardize(X[:,0]).reshape(-1,1),  X[:,1:]))\n",
    "print(f\"Feature shape: \\t\\t{X.shape}\")\n",
    "print(f\"Feature shape: \\t\\t{X_normalized.shape}\")\n",
    "\n",
    "D = jnp.array(df['Treatment'].values.reshape(-1,1)).astype(float)\n",
    "Z = jnp.array(df['Instrument'].values.reshape(-1,1)).astype(float)\n",
    "inputs = jnp.hstack((X_normalized, Z))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Model Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = inputs.shape[1] ; print(f\"Number of Features: {features}\")\n",
    "mlp = MLP([nodes, nodes], jax.nn.relu)\n",
    "final_activation_fn = jax.nn.sigmoid \n",
    "model = Model(mlp, final_activation_fn)\n",
    "supervised_loss = Supervised_Loss(binary_cross_entropy, model.embellished_fwd_pass)\n",
    "yuri = Trainer(supervised_loss, optax.sgd(learning_rate=lr, momentum=0.9), epochs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize random key\n",
    "key = jax.random.PRNGKey(seed)\n",
    "\n",
    "# Create keys\n",
    "key, subkey1, subkey2, subkey3, subkey4 = jax.random.split(key, 5)\n",
    "\n",
    "# Initialize parameters\n",
    "params = ModelParams.init_fn(subkey1, mlp, features)\n",
    "\n",
    "# Split Train and Validation Data\n",
    "# Shuffle the indices\n",
    "idx = jax.random.permutation(subkey2, inputs.shape[0])\n",
    "\n",
    "# Determine the indices for training and validation sets\n",
    "train_size = int((1 - test_size) * inputs.shape[0])\n",
    "train_indices = idx[:train_size]\n",
    "val_indices = idx[train_size:]\n",
    "\n",
    "# Create boolean masks for training and validation sets\n",
    "is_in_train = jnp.isin(jnp.arange(inputs.shape[0]), train_indices)\n",
    "is_in_val = jnp.isin(jnp.arange(inputs.shape[0]), val_indices)\n",
    "\n",
    "# Train the model\n",
    "params, opt_params, train_loss_history, val_loss_history = yuri.train_with_val(params, inputs, D, jnp.ones_like(D), is_in_train, is_in_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Plot Losses**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_loss_history, label='Training')\n",
    "plt.plot(val_loss_history, label='Validation')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Estimate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dhat = np.array(model.fwd_pass(opt_params, inputs))\n",
    "Dhat1 = np.array(model.fwd_pass(opt_params, jnp.hstack((X_normalized, jnp.ones_like(Z)))))\n",
    "Dhat0 = np.array(model.fwd_pass(opt_params, jnp.hstack((X_normalized, jnp.zeros_like(Z)))))\n",
    "residuals = Dhat - (0.5*Dhat1 + 0.5*Dhat0)\n",
    "est = jnp.linalg.lstsq(jnp.hstack((residuals.reshape(-1,1), jnp.ones_like(residuals.reshape(-1,1)))), jnp.array(df['Outcome'].values.reshape(-1,1)))[0][0]\n",
    "df_result = pd.DataFrame({'Estimate': est})\n",
    "est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dhat.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Scatter Comps**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = (df['FStage_Value']*df['Instrument']).values\n",
    "plt.scatter(v, Dhat.reshape(-1,))\n",
    "plt.plot([0,1], [0,1])\n",
    "plt.xlim(0,1)\n",
    "plt.ylim(0,1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Quantile Plot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qs = np.linspace(0, 1, 100)\n",
    "ys1 = np.quantile(Dhat1, qs)\n",
    "ys2 = np.quantile(df['FStage_Value'].values, qs)\n",
    "plt.plot(qs, ys1)\n",
    "plt.plot(qs, ys2)\n",
    "plt.ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Save Results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path for the CSV file\n",
    "file_path = f'./../../../toy-data/exp2/results/nn_{version}_{sample_size}.csv'\n",
    "\n",
    "# Check if the file already exists\n",
    "if not os.path.exists(file_path):\n",
    "    # If the file does not exist, write with headers\n",
    "    df_result[['Estimate']].to_csv(file_path, mode='w', header=True, index=False)\n",
    "else:\n",
    "    # If the file exists, append without headers\n",
    "    df_result[['Estimate']].to_csv(file_path, mode='a', header=False, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
