{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **PyTorch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version: 2.2.2+cu121\n",
      "Cude is available: True\n",
      "Device name: NVIDIA A100-SXM4-40GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "\n",
    "import torch\n",
    "print(f\"Cude is available: {torch.cuda.is_available()}\")\n",
    "print(f\"Device name: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Import Other Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset \n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForCausalLM\n",
    "import numpy as np\n",
    "import evaluate\n",
    "from transformers import TrainingArguments\n",
    "import torch \n",
    "import matplotlib.pyplot as plt \n",
    "from transformers import DataCollatorWithPadding\n",
    "import os \n",
    "from pathlib import Path\n",
    "import random \n",
    "from datasets import Dataset, DatasetDict\n",
    "import warnings\n",
    "from functools import partial\n",
    "from datasets import concatenate_datasets\n",
    "from functools import partial \n",
    "from tqdm import tqdm \n",
    "import textwrap\n",
    "from IPython.display import display\n",
    "from IPython.display import Markdown\n",
    "from trl import SFTTrainer, DataCollatorForCompletionOnlyLM\n",
    "from peft import LoraConfig, get_peft_model \n",
    "from transformers import BitsAndBytesConfig\n",
    "import os \n",
    "import re \n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "warnings.filterwarnings('ignore', message='Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# This cell is tagged with `parameters`\n",
    "model_name = \"google/gemma-1.1-7b-it\" #microsoft/phi-2\" #\"microsoft/phi-2\" #\"#\"meta-llama/Llama-2-7b-chat-hf\" # \"distilbert-base-uncased\" \n",
    "column = 'text'\n",
    "epochs = 1\n",
    "seed = 0\n",
    "verbose = True \n",
    "test_size = 0.5\n",
    "p = 0.0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Set Up Path**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/llmft/results/\n"
     ]
    }
   ],
   "source": [
    "results_folder = str(Path(os.getcwd()).parent.parent.absolute())  + '/results/'\n",
    "figures_folder = str(Path(os.getcwd()).parent.parent.absolute())  + '/figures/'\n",
    "print(results_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = evaluate.load(\"accuracy\")\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Visual Checks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current memory usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n"
     ]
    }
   ],
   "source": [
    "### ---         Print Markdown\n",
    "def to_markdown(text):\n",
    "  text = text.replace('â€¢', '  *')\n",
    "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))\n",
    "### ---\n",
    "\n",
    "### ---         Memory Check\n",
    "def Memory():\n",
    "    print(\"Current memory usage:\")\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')\n",
    "### ---\n",
    "\n",
    "Memory()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Qlora**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Your GPU supports bfloat16: accelerate training with bf16=True\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, get_peft_model \n",
    "from transformers import BitsAndBytesConfig\n",
    "\n",
    "# ----- QUANTIZATION -------# \n",
    "# Activate 4-bit precision base model loading\n",
    "use_4bit = True\n",
    "\n",
    "# Compute dtype for 4-bit base models\n",
    "bnb_4bit_compute_dtype = \"float16\"\n",
    "\n",
    "# Quantization type (fp4 or nf4)\n",
    "bnb_4bit_quant_type = \"nf4\"\n",
    "\n",
    "# Activate nested quantization for 4-bit base models (double quantization)\n",
    "use_nested_quant = True\n",
    "\n",
    "# Load tokenizer and model with QLoRA configuration\n",
    "compute_dtype = getattr(torch, bnb_4bit_compute_dtype)\n",
    "\n",
    "# Enable fp16/bf16 training (set bf16 to True with an A100)\n",
    "fp16 = False\n",
    "bf16 = True\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=use_4bit,\n",
    "    bnb_4bit_quant_type=bnb_4bit_quant_type,\n",
    "    bnb_4bit_compute_dtype=compute_dtype,\n",
    "    bnb_4bit_use_double_quant=use_nested_quant,\n",
    ")\n",
    "\n",
    "# Check GPU compatibility with bfloat16\n",
    "if compute_dtype == torch.float16 and use_4bit:\n",
    "    major, _ = torch.cuda.get_device_capability()\n",
    "    if major >= 8:\n",
    "        print(\"=\" * 80)\n",
    "        print(\"Your GPU supports bfloat16: accelerate training with bf16=True\")\n",
    "        print(\"=\" * 80)\n",
    "\n",
    "# ----- LORA -------# \n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    target_modules=[\"q_proj\", \"o_proj\", \"k_proj\", \"v_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Instantiate Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8407d41dbf814b04a203dc080ef76797",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GenerationConfig {\n",
      "  \"bos_token_id\": 2,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0\n",
      "}\n",
      "\n",
      "Current memory usage:\n",
      "Allocated: 5.2 GB\n",
      "Cached:    5.2 GB\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(model_name, \n",
    "                                             device_map=\"auto\", \n",
    "                                             quantization_config=bnb_config, \n",
    "                                             trust_remote_code=True)# So we can do gradient checkpointing\n",
    "print(model.generation_config)\n",
    "Memory()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Peft Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 25,001,984 || all params: 8,562,682,880 || trainable%: 0.29198773737606876\n",
      "None\n",
      "Current memory usage:\n",
      "Allocated: 5.3 GB\n",
      "Cached:    5.3 GB\n"
     ]
    }
   ],
   "source": [
    "model.config.use_cache = False\n",
    "model.config.pretraining_tp = 1\n",
    "model.config.gradient_checkpointing = False\n",
    "\n",
    "\n",
    "model = get_peft_model(model, lora_config)\n",
    "print(model.print_trainable_parameters())\n",
    "Memory()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Tokenizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.padding_side = 'right'\n",
    "# tokenizer.pad_token_id = tokenizer.eos_token_id \n",
    "# tokenizer.padding_side=\"left\"\n",
    "# model.config.pad_token_id = tokenizer.eos_token_id # ****I DON'T KNOW WHY WE NEED THIS??***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Prompts**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatting_func(example):\n",
    "    text = f\"Quote: {example[column][0]}\\Answer: {example['raw_label'][0]}\"\n",
    "    return [text]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Assessment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_first_true_or_false(text):\n",
    "    # This regular expression pattern looks for 'Yes' or 'No' (case insensitive)\n",
    "    pattern = r'\\b(True|False)\\b'\n",
    "    \n",
    "    # Search the text for the pattern\n",
    "    match = re.search(pattern, text, re.IGNORECASE)\n",
    "    \n",
    "    # If a match is found, return the matched text, otherwise return None\n",
    "    return match.group(0) if match else None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Data set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "933a1692ad7b4e09a884b4b1568e2fda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/425 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4.45M/4.45M [00:00<00:00, 31.1MB/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6716459b51b4e398cc8f1be67186507",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/9797 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(f\"ppower1/covariates\", split='train', download_mode=\"force_redownload\")\n",
    "\n",
    "\n",
    "# Reshuffle and split the combined dataset with a fixed seed\n",
    "new_splits = dataset.train_test_split(test_size=test_size, seed=seed)  # adjust test_size as needed\n",
    "\n",
    "# Create a new DatasetDict with the shuffled splits\n",
    "reshuffled_dataset = DatasetDict({\n",
    "    'train': new_splits['train'],\n",
    "    'test': new_splits['test']\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current memory usage:\n",
      "Allocated: 5.3 GB\n",
      "Cached:    5.3 GB\n",
      "Current memory usage:\n",
      "Allocated: 5.4 GB\n",
      "Cached:    5.4 GB\n"
     ]
    }
   ],
   "source": [
    "# Memory measurement\n",
    "Memory()\n",
    "model_inputs = tokenizer(reshuffled_dataset['train'][column], return_tensors=\"pt\", padding=True).to('cuda')\n",
    "Memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "/home/ubuntu/llms/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:246: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "232da91c73094f5085a8430e714f7d54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4899 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/llms/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:318: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/llms/lib/python3.10/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=reshuffled_dataset['train'],\n",
    "    eval_dataset=reshuffled_dataset['test'],\n",
    "    args=TrainingArguments(\n",
    "        per_device_train_batch_size=4,\n",
    "        per_device_eval_batch_size=4,\n",
    "        load_best_model_at_end=True,\n",
    "\n",
    "        gradient_accumulation_steps=4,\n",
    "        warmup_steps=10,\n",
    "        max_steps=100,\n",
    "        evaluation_strategy = \"steps\",\n",
    "        learning_rate=2e-4,\n",
    "        fp16=True,\n",
    "        logging_steps=1,\n",
    "        output_dir=\"outputs\",\n",
    "        optim=\"paged_adamw_8bit\"\n",
    "    ),\n",
    "    peft_config=lora_config,\n",
    "    formatting_func=formatting_func,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4899, 3)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshuffled_dataset['test'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  2/100 : < :, Epoch 1/100]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/2 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=100, training_loss=0.0023713491344824434, metrics={'train_runtime': 148.7673, 'train_samples_per_second': 10.755, 'train_steps_per_second': 0.672, 'total_flos': 1.264889633891328e+16, 'train_loss': 0.0023713491344824434, 'epoch': 100.0})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps, train_loss =   [i['step'] for i in trainer.state.log_history if 'loss' in i],  [i['loss'] for i in trainer.state.log_history if 'loss' in i]\n",
    "eval_loss = [i['eval_loss'] for i in trainer.state.log_history if 'eval_loss' in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'loss': 0.0019,\n",
       "  'grad_norm': 0.029383506625890732,\n",
       "  'learning_rate': 2e-05,\n",
       "  'epoch': 1.0,\n",
       "  'step': 1},\n",
       " {'eval_loss': 3.604884386062622,\n",
       "  'eval_runtime': 0.3545,\n",
       "  'eval_samples_per_second': 14.106,\n",
       "  'eval_steps_per_second': 5.642,\n",
       "  'epoch': 1.0,\n",
       "  'step': 1},\n",
       " {'loss': 0.0021,\n",
       "  'grad_norm': 0.03982532396912575,\n",
       "  'learning_rate': 4e-05,\n",
       "  'epoch': 2.0,\n",
       "  'step': 2},\n",
       " {'eval_loss': 3.612865447998047,\n",
       "  'eval_runtime': 0.3321,\n",
       "  'eval_samples_per_second': 15.054,\n",
       "  'eval_steps_per_second': 6.021,\n",
       "  'epoch': 2.0,\n",
       "  'step': 2},\n",
       " {'loss': 0.0018,\n",
       "  'grad_norm': 0.02300567366182804,\n",
       "  'learning_rate': 6e-05,\n",
       "  'epoch': 3.0,\n",
       "  'step': 3},\n",
       " {'eval_loss': 3.64190411567688,\n",
       "  'eval_runtime': 0.3299,\n",
       "  'eval_samples_per_second': 15.155,\n",
       "  'eval_steps_per_second': 6.062,\n",
       "  'epoch': 3.0,\n",
       "  'step': 3},\n",
       " {'loss': 0.0023,\n",
       "  'grad_norm': 0.04858225956559181,\n",
       "  'learning_rate': 8e-05,\n",
       "  'epoch': 4.0,\n",
       "  'step': 4},\n",
       " {'eval_loss': 3.682926893234253,\n",
       "  'eval_runtime': 0.33,\n",
       "  'eval_samples_per_second': 15.15,\n",
       "  'eval_steps_per_second': 6.06,\n",
       "  'epoch': 4.0,\n",
       "  'step': 4},\n",
       " {'loss': 0.0042,\n",
       "  'grad_norm': 0.08711913228034973,\n",
       "  'learning_rate': 0.0001,\n",
       "  'epoch': 5.0,\n",
       "  'step': 5},\n",
       " {'eval_loss': 3.6852965354919434,\n",
       "  'eval_runtime': 0.3322,\n",
       "  'eval_samples_per_second': 15.049,\n",
       "  'eval_steps_per_second': 6.02,\n",
       "  'epoch': 5.0,\n",
       "  'step': 5},\n",
       " {'loss': 0.0023,\n",
       "  'grad_norm': 0.02176683209836483,\n",
       "  'learning_rate': 0.00012,\n",
       "  'epoch': 6.0,\n",
       "  'step': 6},\n",
       " {'eval_loss': 3.690761089324951,\n",
       "  'eval_runtime': 0.3303,\n",
       "  'eval_samples_per_second': 15.136,\n",
       "  'eval_steps_per_second': 6.055,\n",
       "  'epoch': 6.0,\n",
       "  'step': 6},\n",
       " {'loss': 0.0023,\n",
       "  'grad_norm': 0.023284796625375748,\n",
       "  'learning_rate': 0.00014,\n",
       "  'epoch': 7.0,\n",
       "  'step': 7},\n",
       " {'eval_loss': 3.6948342323303223,\n",
       "  'eval_runtime': 0.3301,\n",
       "  'eval_samples_per_second': 15.147,\n",
       "  'eval_steps_per_second': 6.059,\n",
       "  'epoch': 7.0,\n",
       "  'step': 7},\n",
       " {'loss': 0.0048,\n",
       "  'grad_norm': 0.0892796665430069,\n",
       "  'learning_rate': 0.00016,\n",
       "  'epoch': 8.0,\n",
       "  'step': 8},\n",
       " {'eval_loss': 3.6895060539245605,\n",
       "  'eval_runtime': 0.3333,\n",
       "  'eval_samples_per_second': 15.003,\n",
       "  'eval_steps_per_second': 6.001,\n",
       "  'epoch': 8.0,\n",
       "  'step': 8},\n",
       " {'loss': 0.0029,\n",
       "  'grad_norm': 0.089319609105587,\n",
       "  'learning_rate': 0.00018,\n",
       "  'epoch': 9.0,\n",
       "  'step': 9},\n",
       " {'eval_loss': 3.688342571258545,\n",
       "  'eval_runtime': 0.33,\n",
       "  'eval_samples_per_second': 15.149,\n",
       "  'eval_steps_per_second': 6.06,\n",
       "  'epoch': 9.0,\n",
       "  'step': 9},\n",
       " {'loss': 0.0049,\n",
       "  'grad_norm': 0.08023085445165634,\n",
       "  'learning_rate': 0.0002,\n",
       "  'epoch': 10.0,\n",
       "  'step': 10},\n",
       " {'eval_loss': 3.6030662059783936,\n",
       "  'eval_runtime': 0.329,\n",
       "  'eval_samples_per_second': 15.199,\n",
       "  'eval_steps_per_second': 6.079,\n",
       "  'epoch': 10.0,\n",
       "  'step': 10},\n",
       " {'loss': 0.0028,\n",
       "  'grad_norm': 0.029925934970378876,\n",
       "  'learning_rate': 0.00019777777777777778,\n",
       "  'epoch': 11.0,\n",
       "  'step': 11},\n",
       " {'eval_loss': 3.5119357109069824,\n",
       "  'eval_runtime': 0.3304,\n",
       "  'eval_samples_per_second': 15.133,\n",
       "  'eval_steps_per_second': 6.053,\n",
       "  'epoch': 11.0,\n",
       "  'step': 11},\n",
       " {'loss': 0.0047,\n",
       "  'grad_norm': 0.056335121393203735,\n",
       "  'learning_rate': 0.00019555555555555556,\n",
       "  'epoch': 12.0,\n",
       "  'step': 12},\n",
       " {'eval_loss': 3.429737091064453,\n",
       "  'eval_runtime': 0.3304,\n",
       "  'eval_samples_per_second': 15.135,\n",
       "  'eval_steps_per_second': 6.054,\n",
       "  'epoch': 12.0,\n",
       "  'step': 12},\n",
       " {'loss': 0.0022,\n",
       "  'grad_norm': 0.021892476826906204,\n",
       "  'learning_rate': 0.00019333333333333333,\n",
       "  'epoch': 13.0,\n",
       "  'step': 13},\n",
       " {'eval_loss': 3.393430709838867,\n",
       "  'eval_runtime': 0.3296,\n",
       "  'eval_samples_per_second': 15.17,\n",
       "  'eval_steps_per_second': 6.068,\n",
       "  'epoch': 13.0,\n",
       "  'step': 13},\n",
       " {'loss': 0.002,\n",
       "  'grad_norm': 0.016055047512054443,\n",
       "  'learning_rate': 0.00019111111111111114,\n",
       "  'epoch': 14.0,\n",
       "  'step': 14},\n",
       " {'eval_loss': 3.412476062774658,\n",
       "  'eval_runtime': 0.3295,\n",
       "  'eval_samples_per_second': 15.175,\n",
       "  'eval_steps_per_second': 6.07,\n",
       "  'epoch': 14.0,\n",
       "  'step': 14},\n",
       " {'loss': 0.002,\n",
       "  'grad_norm': 0.01516757532954216,\n",
       "  'learning_rate': 0.00018888888888888888,\n",
       "  'epoch': 15.0,\n",
       "  'step': 15},\n",
       " {'eval_loss': 3.4429283142089844,\n",
       "  'eval_runtime': 0.331,\n",
       "  'eval_samples_per_second': 15.105,\n",
       "  'eval_steps_per_second': 6.042,\n",
       "  'epoch': 15.0,\n",
       "  'step': 15},\n",
       " {'loss': 0.0036,\n",
       "  'grad_norm': 0.06600741297006607,\n",
       "  'learning_rate': 0.0001866666666666667,\n",
       "  'epoch': 16.0,\n",
       "  'step': 16},\n",
       " {'eval_loss': 3.4828038215637207,\n",
       "  'eval_runtime': 0.3291,\n",
       "  'eval_samples_per_second': 15.193,\n",
       "  'eval_steps_per_second': 6.077,\n",
       "  'epoch': 16.0,\n",
       "  'step': 16},\n",
       " {'loss': 0.0045,\n",
       "  'grad_norm': 0.07399668544530869,\n",
       "  'learning_rate': 0.00018444444444444446,\n",
       "  'epoch': 17.0,\n",
       "  'step': 17},\n",
       " {'eval_loss': 3.4946014881134033,\n",
       "  'eval_runtime': 0.3304,\n",
       "  'eval_samples_per_second': 15.132,\n",
       "  'eval_steps_per_second': 6.053,\n",
       "  'epoch': 17.0,\n",
       "  'step': 17},\n",
       " {'loss': 0.0026,\n",
       "  'grad_norm': 0.037049658596515656,\n",
       "  'learning_rate': 0.00018222222222222224,\n",
       "  'epoch': 18.0,\n",
       "  'step': 18},\n",
       " {'eval_loss': 3.524758815765381,\n",
       "  'eval_runtime': 0.3303,\n",
       "  'eval_samples_per_second': 15.137,\n",
       "  'eval_steps_per_second': 6.055,\n",
       "  'epoch': 18.0,\n",
       "  'step': 18},\n",
       " {'loss': 0.0019,\n",
       "  'grad_norm': 0.01507659163326025,\n",
       "  'learning_rate': 0.00018,\n",
       "  'epoch': 19.0,\n",
       "  'step': 19},\n",
       " {'eval_loss': 3.5639915466308594,\n",
       "  'eval_runtime': 0.3294,\n",
       "  'eval_samples_per_second': 15.181,\n",
       "  'eval_steps_per_second': 6.072,\n",
       "  'epoch': 19.0,\n",
       "  'step': 19},\n",
       " {'loss': 0.002,\n",
       "  'grad_norm': 0.021130474284291267,\n",
       "  'learning_rate': 0.00017777777777777779,\n",
       "  'epoch': 20.0,\n",
       "  'step': 20},\n",
       " {'eval_loss': 3.6111927032470703,\n",
       "  'eval_runtime': 0.3308,\n",
       "  'eval_samples_per_second': 15.114,\n",
       "  'eval_steps_per_second': 6.046,\n",
       "  'epoch': 20.0,\n",
       "  'step': 20},\n",
       " {'loss': 0.0021,\n",
       "  'grad_norm': 0.02425835281610489,\n",
       "  'learning_rate': 0.00017555555555555556,\n",
       "  'epoch': 21.0,\n",
       "  'step': 21},\n",
       " {'eval_loss': 3.6660385131835938,\n",
       "  'eval_runtime': 0.3295,\n",
       "  'eval_samples_per_second': 15.176,\n",
       "  'eval_steps_per_second': 6.07,\n",
       "  'epoch': 21.0,\n",
       "  'step': 21},\n",
       " {'loss': 0.0032,\n",
       "  'grad_norm': 0.04219463840126991,\n",
       "  'learning_rate': 0.00017333333333333334,\n",
       "  'epoch': 22.0,\n",
       "  'step': 22},\n",
       " {'eval_loss': 3.7293529510498047,\n",
       "  'eval_runtime': 0.3306,\n",
       "  'eval_samples_per_second': 15.122,\n",
       "  'eval_steps_per_second': 6.049,\n",
       "  'epoch': 22.0,\n",
       "  'step': 22},\n",
       " {'loss': 0.0022,\n",
       "  'grad_norm': 0.027996186167001724,\n",
       "  'learning_rate': 0.0001711111111111111,\n",
       "  'epoch': 23.0,\n",
       "  'step': 23},\n",
       " {'eval_loss': 3.7940285205841064,\n",
       "  'eval_runtime': 0.3295,\n",
       "  'eval_samples_per_second': 15.174,\n",
       "  'eval_steps_per_second': 6.07,\n",
       "  'epoch': 23.0,\n",
       "  'step': 23},\n",
       " {'loss': 0.0027,\n",
       "  'grad_norm': 0.03634435683488846,\n",
       "  'learning_rate': 0.00016888888888888889,\n",
       "  'epoch': 24.0,\n",
       "  'step': 24},\n",
       " {'eval_loss': 3.8373539447784424,\n",
       "  'eval_runtime': 0.3303,\n",
       "  'eval_samples_per_second': 15.139,\n",
       "  'eval_steps_per_second': 6.055,\n",
       "  'epoch': 24.0,\n",
       "  'step': 24},\n",
       " {'loss': 0.0025,\n",
       "  'grad_norm': 0.03982535004615784,\n",
       "  'learning_rate': 0.0001666666666666667,\n",
       "  'epoch': 25.0,\n",
       "  'step': 25},\n",
       " {'eval_loss': 3.8861355781555176,\n",
       "  'eval_runtime': 0.331,\n",
       "  'eval_samples_per_second': 15.108,\n",
       "  'eval_steps_per_second': 6.043,\n",
       "  'epoch': 25.0,\n",
       "  'step': 25},\n",
       " {'loss': 0.002,\n",
       "  'grad_norm': 0.018730562180280685,\n",
       "  'learning_rate': 0.00016444444444444444,\n",
       "  'epoch': 26.0,\n",
       "  'step': 26},\n",
       " {'eval_loss': 3.9310355186462402,\n",
       "  'eval_runtime': 0.3302,\n",
       "  'eval_samples_per_second': 15.141,\n",
       "  'eval_steps_per_second': 6.056,\n",
       "  'epoch': 26.0,\n",
       "  'step': 26},\n",
       " {'loss': 0.0021,\n",
       "  'grad_norm': 0.02887202426791191,\n",
       "  'learning_rate': 0.00016222222222222224,\n",
       "  'epoch': 27.0,\n",
       "  'step': 27},\n",
       " {'eval_loss': 3.9654946327209473,\n",
       "  'eval_runtime': 0.3307,\n",
       "  'eval_samples_per_second': 15.121,\n",
       "  'eval_steps_per_second': 6.049,\n",
       "  'epoch': 27.0,\n",
       "  'step': 27},\n",
       " {'loss': 0.0032,\n",
       "  'grad_norm': 0.05573228746652603,\n",
       "  'learning_rate': 0.00016,\n",
       "  'epoch': 28.0,\n",
       "  'step': 28},\n",
       " {'eval_loss': 3.9956371784210205,\n",
       "  'eval_runtime': 0.3297,\n",
       "  'eval_samples_per_second': 15.166,\n",
       "  'eval_steps_per_second': 6.067,\n",
       "  'epoch': 28.0,\n",
       "  'step': 28},\n",
       " {'loss': 0.0017,\n",
       "  'grad_norm': 0.007126673124730587,\n",
       "  'learning_rate': 0.0001577777777777778,\n",
       "  'epoch': 29.0,\n",
       "  'step': 29},\n",
       " {'eval_loss': 4.023880481719971,\n",
       "  'eval_runtime': 0.3303,\n",
       "  'eval_samples_per_second': 15.137,\n",
       "  'eval_steps_per_second': 6.055,\n",
       "  'epoch': 29.0,\n",
       "  'step': 29},\n",
       " {'loss': 0.0017,\n",
       "  'grad_norm': 0.008263402618467808,\n",
       "  'learning_rate': 0.00015555555555555556,\n",
       "  'epoch': 30.0,\n",
       "  'step': 30},\n",
       " {'eval_loss': 4.04718017578125,\n",
       "  'eval_runtime': 0.331,\n",
       "  'eval_samples_per_second': 15.107,\n",
       "  'eval_steps_per_second': 6.043,\n",
       "  'epoch': 30.0,\n",
       "  'step': 30},\n",
       " {'loss': 0.0022,\n",
       "  'grad_norm': 0.024374285712838173,\n",
       "  'learning_rate': 0.00015333333333333334,\n",
       "  'epoch': 31.0,\n",
       "  'step': 31},\n",
       " {'eval_loss': 4.07376766204834,\n",
       "  'eval_runtime': 0.3309,\n",
       "  'eval_samples_per_second': 15.109,\n",
       "  'eval_steps_per_second': 6.043,\n",
       "  'epoch': 31.0,\n",
       "  'step': 31},\n",
       " {'loss': 0.0025,\n",
       "  'grad_norm': 0.0361582487821579,\n",
       "  'learning_rate': 0.0001511111111111111,\n",
       "  'epoch': 32.0,\n",
       "  'step': 32},\n",
       " {'eval_loss': 4.098328113555908,\n",
       "  'eval_runtime': 0.3307,\n",
       "  'eval_samples_per_second': 15.118,\n",
       "  'eval_steps_per_second': 6.047,\n",
       "  'epoch': 32.0,\n",
       "  'step': 32},\n",
       " {'loss': 0.0036,\n",
       "  'grad_norm': 0.05620299279689789,\n",
       "  'learning_rate': 0.0001488888888888889,\n",
       "  'epoch': 33.0,\n",
       "  'step': 33},\n",
       " {'eval_loss': 4.125700950622559,\n",
       "  'eval_runtime': 0.3303,\n",
       "  'eval_samples_per_second': 15.139,\n",
       "  'eval_steps_per_second': 6.055,\n",
       "  'epoch': 33.0,\n",
       "  'step': 33},\n",
       " {'loss': 0.0024,\n",
       "  'grad_norm': 0.032673463225364685,\n",
       "  'learning_rate': 0.00014666666666666666,\n",
       "  'epoch': 34.0,\n",
       "  'step': 34},\n",
       " {'eval_loss': 4.145389556884766,\n",
       "  'eval_runtime': 0.3304,\n",
       "  'eval_samples_per_second': 15.134,\n",
       "  'eval_steps_per_second': 6.054,\n",
       "  'epoch': 34.0,\n",
       "  'step': 34},\n",
       " {'loss': 0.0023,\n",
       "  'grad_norm': 0.03485282137989998,\n",
       "  'learning_rate': 0.00014444444444444444,\n",
       "  'epoch': 35.0,\n",
       "  'step': 35},\n",
       " {'eval_loss': 4.161224842071533,\n",
       "  'eval_runtime': 0.3304,\n",
       "  'eval_samples_per_second': 15.134,\n",
       "  'eval_steps_per_second': 6.054,\n",
       "  'epoch': 35.0,\n",
       "  'step': 35},\n",
       " {'loss': 0.0022,\n",
       "  'grad_norm': 0.020277604460716248,\n",
       "  'learning_rate': 0.00014222222222222224,\n",
       "  'epoch': 36.0,\n",
       "  'step': 36},\n",
       " {'eval_loss': 4.170159816741943,\n",
       "  'eval_runtime': 0.3303,\n",
       "  'eval_samples_per_second': 15.14,\n",
       "  'eval_steps_per_second': 6.056,\n",
       "  'epoch': 36.0,\n",
       "  'step': 36},\n",
       " {'loss': 0.0031,\n",
       "  'grad_norm': 0.06640419363975525,\n",
       "  'learning_rate': 0.00014,\n",
       "  'epoch': 37.0,\n",
       "  'step': 37},\n",
       " {'eval_loss': 4.182127475738525,\n",
       "  'eval_runtime': 0.3414,\n",
       "  'eval_samples_per_second': 14.644,\n",
       "  'eval_steps_per_second': 5.858,\n",
       "  'epoch': 37.0,\n",
       "  'step': 37},\n",
       " {'loss': 0.0023,\n",
       "  'grad_norm': 0.016141271218657494,\n",
       "  'learning_rate': 0.0001377777777777778,\n",
       "  'epoch': 38.0,\n",
       "  'step': 38},\n",
       " {'eval_loss': 4.1893205642700195,\n",
       "  'eval_runtime': 0.3322,\n",
       "  'eval_samples_per_second': 15.053,\n",
       "  'eval_steps_per_second': 6.021,\n",
       "  'epoch': 38.0,\n",
       "  'step': 38},\n",
       " {'loss': 0.0023,\n",
       "  'grad_norm': 0.02546260692179203,\n",
       "  'learning_rate': 0.00013555555555555556,\n",
       "  'epoch': 39.0,\n",
       "  'step': 39},\n",
       " {'eval_loss': 4.194342136383057,\n",
       "  'eval_runtime': 0.3298,\n",
       "  'eval_samples_per_second': 15.159,\n",
       "  'eval_steps_per_second': 6.064,\n",
       "  'epoch': 39.0,\n",
       "  'step': 39},\n",
       " {'loss': 0.0022,\n",
       "  'grad_norm': 0.016794655472040176,\n",
       "  'learning_rate': 0.00013333333333333334,\n",
       "  'epoch': 40.0,\n",
       "  'step': 40},\n",
       " {'eval_loss': 4.194412708282471,\n",
       "  'eval_runtime': 0.3347,\n",
       "  'eval_samples_per_second': 14.941,\n",
       "  'eval_steps_per_second': 5.976,\n",
       "  'epoch': 40.0,\n",
       "  'step': 40},\n",
       " {'loss': 0.0036,\n",
       "  'grad_norm': 0.035293132066726685,\n",
       "  'learning_rate': 0.00013111111111111111,\n",
       "  'epoch': 41.0,\n",
       "  'step': 41},\n",
       " {'eval_loss': 4.187071800231934,\n",
       "  'eval_runtime': 0.331,\n",
       "  'eval_samples_per_second': 15.105,\n",
       "  'eval_steps_per_second': 6.042,\n",
       "  'epoch': 41.0,\n",
       "  'step': 41},\n",
       " {'loss': 0.0029,\n",
       "  'grad_norm': 0.035606954246759415,\n",
       "  'learning_rate': 0.00012888888888888892,\n",
       "  'epoch': 42.0,\n",
       "  'step': 42},\n",
       " {'eval_loss': 4.178476333618164,\n",
       "  'eval_runtime': 0.3304,\n",
       "  'eval_samples_per_second': 15.131,\n",
       "  'eval_steps_per_second': 6.052,\n",
       "  'epoch': 42.0,\n",
       "  'step': 42},\n",
       " {'loss': 0.002,\n",
       "  'grad_norm': 0.030367456376552582,\n",
       "  'learning_rate': 0.00012666666666666666,\n",
       "  'epoch': 43.0,\n",
       "  'step': 43},\n",
       " {'eval_loss': 4.168183326721191,\n",
       "  'eval_runtime': 0.3307,\n",
       "  'eval_samples_per_second': 15.118,\n",
       "  'eval_steps_per_second': 6.047,\n",
       "  'epoch': 43.0,\n",
       "  'step': 43},\n",
       " {'loss': 0.0021,\n",
       "  'grad_norm': 0.025746997445821762,\n",
       "  'learning_rate': 0.00012444444444444444,\n",
       "  'epoch': 44.0,\n",
       "  'step': 44},\n",
       " {'eval_loss': 4.158544063568115,\n",
       "  'eval_runtime': 0.3309,\n",
       "  'eval_samples_per_second': 15.11,\n",
       "  'eval_steps_per_second': 6.044,\n",
       "  'epoch': 44.0,\n",
       "  'step': 44},\n",
       " {'loss': 0.0019,\n",
       "  'grad_norm': 0.02271757461130619,\n",
       "  'learning_rate': 0.00012222222222222224,\n",
       "  'epoch': 45.0,\n",
       "  'step': 45},\n",
       " {'eval_loss': 4.15204381942749,\n",
       "  'eval_runtime': 0.3299,\n",
       "  'eval_samples_per_second': 15.158,\n",
       "  'eval_steps_per_second': 6.063,\n",
       "  'epoch': 45.0,\n",
       "  'step': 45},\n",
       " {'loss': 0.003,\n",
       "  'grad_norm': 0.04662381857633591,\n",
       "  'learning_rate': 0.00012,\n",
       "  'epoch': 46.0,\n",
       "  'step': 46},\n",
       " {'eval_loss': 4.142945289611816,\n",
       "  'eval_runtime': 0.3319,\n",
       "  'eval_samples_per_second': 15.065,\n",
       "  'eval_steps_per_second': 6.026,\n",
       "  'epoch': 46.0,\n",
       "  'step': 46},\n",
       " {'loss': 0.0017,\n",
       "  'grad_norm': 0.006588376592844725,\n",
       "  'learning_rate': 0.00011777777777777779,\n",
       "  'epoch': 47.0,\n",
       "  'step': 47},\n",
       " {'eval_loss': 4.136449813842773,\n",
       "  'eval_runtime': 0.332,\n",
       "  'eval_samples_per_second': 15.058,\n",
       "  'eval_steps_per_second': 6.023,\n",
       "  'epoch': 47.0,\n",
       "  'step': 47},\n",
       " {'loss': 0.002,\n",
       "  'grad_norm': 0.019303670153021812,\n",
       "  'learning_rate': 0.00011555555555555555,\n",
       "  'epoch': 48.0,\n",
       "  'step': 48},\n",
       " {'eval_loss': 4.130318641662598,\n",
       "  'eval_runtime': 0.3305,\n",
       "  'eval_samples_per_second': 15.127,\n",
       "  'eval_steps_per_second': 6.051,\n",
       "  'epoch': 48.0,\n",
       "  'step': 48},\n",
       " {'loss': 0.0028,\n",
       "  'grad_norm': 0.037829313427209854,\n",
       "  'learning_rate': 0.00011333333333333334,\n",
       "  'epoch': 49.0,\n",
       "  'step': 49},\n",
       " {'eval_loss': 4.12294340133667,\n",
       "  'eval_runtime': 0.3306,\n",
       "  'eval_samples_per_second': 15.125,\n",
       "  'eval_steps_per_second': 6.05,\n",
       "  'epoch': 49.0,\n",
       "  'step': 49},\n",
       " {'loss': 0.0033,\n",
       "  'grad_norm': 0.03879326209425926,\n",
       "  'learning_rate': 0.00011111111111111112,\n",
       "  'epoch': 50.0,\n",
       "  'step': 50},\n",
       " {'eval_loss': 4.1191582679748535,\n",
       "  'eval_runtime': 0.3298,\n",
       "  'eval_samples_per_second': 15.159,\n",
       "  'eval_steps_per_second': 6.064,\n",
       "  'epoch': 50.0,\n",
       "  'step': 50},\n",
       " {'loss': 0.0032,\n",
       "  'grad_norm': 0.03768846020102501,\n",
       "  'learning_rate': 0.00010888888888888889,\n",
       "  'epoch': 51.0,\n",
       "  'step': 51},\n",
       " {'eval_loss': 4.115606307983398,\n",
       "  'eval_runtime': 0.3309,\n",
       "  'eval_samples_per_second': 15.111,\n",
       "  'eval_steps_per_second': 6.044,\n",
       "  'epoch': 51.0,\n",
       "  'step': 51},\n",
       " {'loss': 0.0022,\n",
       "  'grad_norm': 0.030799590051174164,\n",
       "  'learning_rate': 0.00010666666666666667,\n",
       "  'epoch': 52.0,\n",
       "  'step': 52},\n",
       " {'eval_loss': 4.112948894500732,\n",
       "  'eval_runtime': 0.3322,\n",
       "  'eval_samples_per_second': 15.052,\n",
       "  'eval_steps_per_second': 6.021,\n",
       "  'epoch': 52.0,\n",
       "  'step': 52},\n",
       " {'loss': 0.0019,\n",
       "  'grad_norm': 0.023214347660541534,\n",
       "  'learning_rate': 0.00010444444444444445,\n",
       "  'epoch': 53.0,\n",
       "  'step': 53},\n",
       " {'eval_loss': 4.112214088439941,\n",
       "  'eval_runtime': 0.3308,\n",
       "  'eval_samples_per_second': 15.115,\n",
       "  'eval_steps_per_second': 6.046,\n",
       "  'epoch': 53.0,\n",
       "  'step': 53},\n",
       " {'loss': 0.0023,\n",
       "  'grad_norm': 0.034402407705783844,\n",
       "  'learning_rate': 0.00010222222222222222,\n",
       "  'epoch': 54.0,\n",
       "  'step': 54},\n",
       " {'eval_loss': 4.114624977111816,\n",
       "  'eval_runtime': 0.3309,\n",
       "  'eval_samples_per_second': 15.109,\n",
       "  'eval_steps_per_second': 6.043,\n",
       "  'epoch': 54.0,\n",
       "  'step': 54},\n",
       " {'loss': 0.0021,\n",
       "  'grad_norm': 0.0337434783577919,\n",
       "  'learning_rate': 0.0001,\n",
       "  'epoch': 55.0,\n",
       "  'step': 55},\n",
       " {'eval_loss': 4.115052700042725,\n",
       "  'eval_runtime': 0.332,\n",
       "  'eval_samples_per_second': 15.061,\n",
       "  'eval_steps_per_second': 6.024,\n",
       "  'epoch': 55.0,\n",
       "  'step': 55},\n",
       " {'loss': 0.0023,\n",
       "  'grad_norm': 0.024996371939778328,\n",
       "  'learning_rate': 9.777777777777778e-05,\n",
       "  'epoch': 56.0,\n",
       "  'step': 56},\n",
       " {'eval_loss': 4.119382381439209,\n",
       "  'eval_runtime': 0.3313,\n",
       "  'eval_samples_per_second': 15.092,\n",
       "  'eval_steps_per_second': 6.037,\n",
       "  'epoch': 56.0,\n",
       "  'step': 56},\n",
       " {'loss': 0.0021,\n",
       "  'grad_norm': 0.028246166184544563,\n",
       "  'learning_rate': 9.555555555555557e-05,\n",
       "  'epoch': 57.0,\n",
       "  'step': 57},\n",
       " {'eval_loss': 4.123908519744873,\n",
       "  'eval_runtime': 0.3317,\n",
       "  'eval_samples_per_second': 15.076,\n",
       "  'eval_steps_per_second': 6.03,\n",
       "  'epoch': 57.0,\n",
       "  'step': 57},\n",
       " {'loss': 0.0027,\n",
       "  'grad_norm': 0.028311695903539658,\n",
       "  'learning_rate': 9.333333333333334e-05,\n",
       "  'epoch': 58.0,\n",
       "  'step': 58},\n",
       " {'eval_loss': 4.1273016929626465,\n",
       "  'eval_runtime': 0.3308,\n",
       "  'eval_samples_per_second': 15.113,\n",
       "  'eval_steps_per_second': 6.045,\n",
       "  'epoch': 58.0,\n",
       "  'step': 58},\n",
       " {'loss': 0.0024,\n",
       "  'grad_norm': 0.026699012145400047,\n",
       "  'learning_rate': 9.111111111111112e-05,\n",
       "  'epoch': 59.0,\n",
       "  'step': 59},\n",
       " {'eval_loss': 4.132905006408691,\n",
       "  'eval_runtime': 0.331,\n",
       "  'eval_samples_per_second': 15.108,\n",
       "  'eval_steps_per_second': 6.043,\n",
       "  'epoch': 59.0,\n",
       "  'step': 59},\n",
       " {'loss': 0.0025,\n",
       "  'grad_norm': 0.023858292028307915,\n",
       "  'learning_rate': 8.888888888888889e-05,\n",
       "  'epoch': 60.0,\n",
       "  'step': 60},\n",
       " {'eval_loss': 4.134176731109619,\n",
       "  'eval_runtime': 0.3316,\n",
       "  'eval_samples_per_second': 15.079,\n",
       "  'eval_steps_per_second': 6.032,\n",
       "  'epoch': 60.0,\n",
       "  'step': 60},\n",
       " {'loss': 0.0029,\n",
       "  'grad_norm': 0.02885223738849163,\n",
       "  'learning_rate': 8.666666666666667e-05,\n",
       "  'epoch': 61.0,\n",
       "  'step': 61},\n",
       " {'eval_loss': 4.137082576751709,\n",
       "  'eval_runtime': 0.3311,\n",
       "  'eval_samples_per_second': 15.101,\n",
       "  'eval_steps_per_second': 6.041,\n",
       "  'epoch': 61.0,\n",
       "  'step': 61},\n",
       " {'loss': 0.0021,\n",
       "  'grad_norm': 0.018243174999952316,\n",
       "  'learning_rate': 8.444444444444444e-05,\n",
       "  'epoch': 62.0,\n",
       "  'step': 62},\n",
       " {'eval_loss': 4.141520023345947,\n",
       "  'eval_runtime': 0.331,\n",
       "  'eval_samples_per_second': 15.108,\n",
       "  'eval_steps_per_second': 6.043,\n",
       "  'epoch': 62.0,\n",
       "  'step': 62},\n",
       " {'loss': 0.0021,\n",
       "  'grad_norm': 0.017016999423503876,\n",
       "  'learning_rate': 8.222222222222222e-05,\n",
       "  'epoch': 63.0,\n",
       "  'step': 63},\n",
       " {'eval_loss': 4.143871784210205,\n",
       "  'eval_runtime': 0.331,\n",
       "  'eval_samples_per_second': 15.108,\n",
       "  'eval_steps_per_second': 6.043,\n",
       "  'epoch': 63.0,\n",
       "  'step': 63},\n",
       " {'loss': 0.0019,\n",
       "  'grad_norm': 0.013634014874696732,\n",
       "  'learning_rate': 8e-05,\n",
       "  'epoch': 64.0,\n",
       "  'step': 64},\n",
       " {'eval_loss': 4.14798641204834,\n",
       "  'eval_runtime': 0.3311,\n",
       "  'eval_samples_per_second': 15.099,\n",
       "  'eval_steps_per_second': 6.04,\n",
       "  'epoch': 64.0,\n",
       "  'step': 64},\n",
       " {'loss': 0.0019,\n",
       "  'grad_norm': 0.0163179449737072,\n",
       "  'learning_rate': 7.777777777777778e-05,\n",
       "  'epoch': 65.0,\n",
       "  'step': 65},\n",
       " {'eval_loss': 4.153565883636475,\n",
       "  'eval_runtime': 0.3311,\n",
       "  'eval_samples_per_second': 15.1,\n",
       "  'eval_steps_per_second': 6.04,\n",
       "  'epoch': 65.0,\n",
       "  'step': 65},\n",
       " {'loss': 0.0027,\n",
       "  'grad_norm': 0.0358550138771534,\n",
       "  'learning_rate': 7.555555555555556e-05,\n",
       "  'epoch': 66.0,\n",
       "  'step': 66},\n",
       " {'eval_loss': 4.15756893157959,\n",
       "  'eval_runtime': 0.3322,\n",
       "  'eval_samples_per_second': 15.052,\n",
       "  'eval_steps_per_second': 6.021,\n",
       "  'epoch': 66.0,\n",
       "  'step': 66},\n",
       " {'loss': 0.0022,\n",
       "  'grad_norm': 0.019502336159348488,\n",
       "  'learning_rate': 7.333333333333333e-05,\n",
       "  'epoch': 67.0,\n",
       "  'step': 67},\n",
       " {'eval_loss': 4.159976005554199,\n",
       "  'eval_runtime': 0.3307,\n",
       "  'eval_samples_per_second': 15.118,\n",
       "  'eval_steps_per_second': 6.047,\n",
       "  'epoch': 67.0,\n",
       "  'step': 67},\n",
       " {'loss': 0.0018,\n",
       "  'grad_norm': 0.008205004967749119,\n",
       "  'learning_rate': 7.111111111111112e-05,\n",
       "  'epoch': 68.0,\n",
       "  'step': 68},\n",
       " {'eval_loss': 4.163519382476807,\n",
       "  'eval_runtime': 0.331,\n",
       "  'eval_samples_per_second': 15.104,\n",
       "  'eval_steps_per_second': 6.042,\n",
       "  'epoch': 68.0,\n",
       "  'step': 68},\n",
       " {'loss': 0.0017,\n",
       "  'grad_norm': 0.008636338636279106,\n",
       "  'learning_rate': 6.88888888888889e-05,\n",
       "  'epoch': 69.0,\n",
       "  'step': 69},\n",
       " {'eval_loss': 4.168628215789795,\n",
       "  'eval_runtime': 0.3314,\n",
       "  'eval_samples_per_second': 15.088,\n",
       "  'eval_steps_per_second': 6.035,\n",
       "  'epoch': 69.0,\n",
       "  'step': 69},\n",
       " {'loss': 0.0025,\n",
       "  'grad_norm': 0.03187701106071472,\n",
       "  'learning_rate': 6.666666666666667e-05,\n",
       "  'epoch': 70.0,\n",
       "  'step': 70},\n",
       " {'eval_loss': 4.173121452331543,\n",
       "  'eval_runtime': 0.3322,\n",
       "  'eval_samples_per_second': 15.05,\n",
       "  'eval_steps_per_second': 6.02,\n",
       "  'epoch': 70.0,\n",
       "  'step': 70},\n",
       " {'loss': 0.0022,\n",
       "  'grad_norm': 0.028293713927268982,\n",
       "  'learning_rate': 6.444444444444446e-05,\n",
       "  'epoch': 71.0,\n",
       "  'step': 71},\n",
       " {'eval_loss': 4.179540157318115,\n",
       "  'eval_runtime': 0.3318,\n",
       "  'eval_samples_per_second': 15.07,\n",
       "  'eval_steps_per_second': 6.028,\n",
       "  'epoch': 71.0,\n",
       "  'step': 71},\n",
       " {'loss': 0.002,\n",
       "  'grad_norm': 0.02019454352557659,\n",
       "  'learning_rate': 6.222222222222222e-05,\n",
       "  'epoch': 72.0,\n",
       "  'step': 72},\n",
       " {'eval_loss': 4.1843414306640625,\n",
       "  'eval_runtime': 0.3304,\n",
       "  'eval_samples_per_second': 15.133,\n",
       "  'eval_steps_per_second': 6.053,\n",
       "  'epoch': 72.0,\n",
       "  'step': 72},\n",
       " {'loss': 0.002,\n",
       "  'grad_norm': 0.016214851289987564,\n",
       "  'learning_rate': 6e-05,\n",
       "  'epoch': 73.0,\n",
       "  'step': 73},\n",
       " {'eval_loss': 4.188549518585205,\n",
       "  'eval_runtime': 0.3303,\n",
       "  'eval_samples_per_second': 15.138,\n",
       "  'eval_steps_per_second': 6.055,\n",
       "  'epoch': 73.0,\n",
       "  'step': 73},\n",
       " {'loss': 0.0019,\n",
       "  'grad_norm': 0.014666014350950718,\n",
       "  'learning_rate': 5.7777777777777776e-05,\n",
       "  'epoch': 74.0,\n",
       "  'step': 74},\n",
       " {'eval_loss': 4.194381237030029,\n",
       "  'eval_runtime': 0.3314,\n",
       "  'eval_samples_per_second': 15.086,\n",
       "  'eval_steps_per_second': 6.034,\n",
       "  'epoch': 74.0,\n",
       "  'step': 74},\n",
       " {'loss': 0.002,\n",
       "  'grad_norm': 0.027853772044181824,\n",
       "  'learning_rate': 5.555555555555556e-05,\n",
       "  'epoch': 75.0,\n",
       "  'step': 75},\n",
       " {'eval_loss': 4.198029518127441,\n",
       "  'eval_runtime': 0.33,\n",
       "  'eval_samples_per_second': 15.15,\n",
       "  'eval_steps_per_second': 6.06,\n",
       "  'epoch': 75.0,\n",
       "  'step': 75},\n",
       " {'loss': 0.0021,\n",
       "  'grad_norm': 0.02126021310687065,\n",
       "  'learning_rate': 5.333333333333333e-05,\n",
       "  'epoch': 76.0,\n",
       "  'step': 76},\n",
       " {'eval_loss': 4.202306270599365,\n",
       "  'eval_runtime': 0.3319,\n",
       "  'eval_samples_per_second': 15.066,\n",
       "  'eval_steps_per_second': 6.026,\n",
       "  'epoch': 76.0,\n",
       "  'step': 76},\n",
       " {'loss': 0.0017,\n",
       "  'grad_norm': 0.01029931753873825,\n",
       "  'learning_rate': 5.111111111111111e-05,\n",
       "  'epoch': 77.0,\n",
       "  'step': 77},\n",
       " {'eval_loss': 4.207810878753662,\n",
       "  'eval_runtime': 0.3319,\n",
       "  'eval_samples_per_second': 15.065,\n",
       "  'eval_steps_per_second': 6.026,\n",
       "  'epoch': 77.0,\n",
       "  'step': 77},\n",
       " {'loss': 0.0017,\n",
       "  'grad_norm': 0.012762278318405151,\n",
       "  'learning_rate': 4.888888888888889e-05,\n",
       "  'epoch': 78.0,\n",
       "  'step': 78},\n",
       " {'eval_loss': 4.21107292175293,\n",
       "  'eval_runtime': 0.331,\n",
       "  'eval_samples_per_second': 15.105,\n",
       "  'eval_steps_per_second': 6.042,\n",
       "  'epoch': 78.0,\n",
       "  'step': 78},\n",
       " {'loss': 0.002,\n",
       "  'grad_norm': 0.01680948957800865,\n",
       "  'learning_rate': 4.666666666666667e-05,\n",
       "  'epoch': 79.0,\n",
       "  'step': 79},\n",
       " {'eval_loss': 4.215182304382324,\n",
       "  'eval_runtime': 0.331,\n",
       "  'eval_samples_per_second': 15.106,\n",
       "  'eval_steps_per_second': 6.043,\n",
       "  'epoch': 79.0,\n",
       "  'step': 79},\n",
       " {'loss': 0.0018,\n",
       "  'grad_norm': 0.0185807216912508,\n",
       "  'learning_rate': 4.4444444444444447e-05,\n",
       "  'epoch': 80.0,\n",
       "  'step': 80},\n",
       " {'eval_loss': 4.217563629150391,\n",
       "  'eval_runtime': 0.3337,\n",
       "  'eval_samples_per_second': 14.984,\n",
       "  'eval_steps_per_second': 5.994,\n",
       "  'epoch': 80.0,\n",
       "  'step': 80},\n",
       " {'loss': 0.002,\n",
       "  'grad_norm': 0.016689155250787735,\n",
       "  'learning_rate': 4.222222222222222e-05,\n",
       "  'epoch': 81.0,\n",
       "  'step': 81},\n",
       " {'eval_loss': 4.219802379608154,\n",
       "  'eval_runtime': 0.3331,\n",
       "  'eval_samples_per_second': 15.013,\n",
       "  'eval_steps_per_second': 6.005,\n",
       "  'epoch': 81.0,\n",
       "  'step': 81},\n",
       " {'loss': 0.0024,\n",
       "  'grad_norm': 0.03230658173561096,\n",
       "  'learning_rate': 4e-05,\n",
       "  'epoch': 82.0,\n",
       "  'step': 82},\n",
       " {'eval_loss': 4.222795486450195,\n",
       "  'eval_runtime': 0.33,\n",
       "  'eval_samples_per_second': 15.149,\n",
       "  'eval_steps_per_second': 6.06,\n",
       "  'epoch': 82.0,\n",
       "  'step': 82},\n",
       " {'loss': 0.0018,\n",
       "  'grad_norm': 0.01951615884900093,\n",
       "  'learning_rate': 3.777777777777778e-05,\n",
       "  'epoch': 83.0,\n",
       "  'step': 83},\n",
       " {'eval_loss': 4.225140571594238,\n",
       "  'eval_runtime': 0.3299,\n",
       "  'eval_samples_per_second': 15.155,\n",
       "  'eval_steps_per_second': 6.062,\n",
       "  'epoch': 83.0,\n",
       "  'step': 83},\n",
       " {'loss': 0.0025,\n",
       "  'grad_norm': 0.029119525104761124,\n",
       "  'learning_rate': 3.555555555555556e-05,\n",
       "  'epoch': 84.0,\n",
       "  'step': 84},\n",
       " {'eval_loss': 4.226541042327881,\n",
       "  'eval_runtime': 0.3316,\n",
       "  'eval_samples_per_second': 15.077,\n",
       "  'eval_steps_per_second': 6.031,\n",
       "  'epoch': 84.0,\n",
       "  'step': 84},\n",
       " {'loss': 0.0026,\n",
       "  'grad_norm': 0.03089452162384987,\n",
       "  'learning_rate': 3.3333333333333335e-05,\n",
       "  'epoch': 85.0,\n",
       "  'step': 85},\n",
       " {'eval_loss': 4.228739261627197,\n",
       "  'eval_runtime': 0.3301,\n",
       "  'eval_samples_per_second': 15.149,\n",
       "  'eval_steps_per_second': 6.06,\n",
       "  'epoch': 85.0,\n",
       "  'step': 85},\n",
       " {'loss': 0.0017,\n",
       "  'grad_norm': 0.012005062773823738,\n",
       "  'learning_rate': 3.111111111111111e-05,\n",
       "  'epoch': 86.0,\n",
       "  'step': 86},\n",
       " {'eval_loss': 4.229001522064209,\n",
       "  'eval_runtime': 0.3493,\n",
       "  'eval_samples_per_second': 14.313,\n",
       "  'eval_steps_per_second': 5.725,\n",
       "  'epoch': 86.0,\n",
       "  'step': 86},\n",
       " {'loss': 0.0017,\n",
       "  'grad_norm': 0.012089239433407784,\n",
       "  'learning_rate': 2.8888888888888888e-05,\n",
       "  'epoch': 87.0,\n",
       "  'step': 87},\n",
       " {'eval_loss': 4.230560302734375,\n",
       "  'eval_runtime': 0.332,\n",
       "  'eval_samples_per_second': 15.059,\n",
       "  'eval_steps_per_second': 6.024,\n",
       "  'epoch': 87.0,\n",
       "  'step': 87},\n",
       " {'loss': 0.0019,\n",
       "  'grad_norm': 0.0149226114153862,\n",
       "  'learning_rate': 2.6666666666666667e-05,\n",
       "  'epoch': 88.0,\n",
       "  'step': 88},\n",
       " {'eval_loss': 4.230584621429443,\n",
       "  'eval_runtime': 0.3307,\n",
       "  'eval_samples_per_second': 15.12,\n",
       "  'eval_steps_per_second': 6.048,\n",
       "  'epoch': 88.0,\n",
       "  'step': 88},\n",
       " {'loss': 0.0023,\n",
       "  'grad_norm': 0.02563093975186348,\n",
       "  'learning_rate': 2.4444444444444445e-05,\n",
       "  'epoch': 89.0,\n",
       "  'step': 89},\n",
       " {'eval_loss': 4.230401039123535,\n",
       "  'eval_runtime': 0.3315,\n",
       "  'eval_samples_per_second': 15.085,\n",
       "  'eval_steps_per_second': 6.034,\n",
       "  'epoch': 89.0,\n",
       "  'step': 89},\n",
       " {'loss': 0.0019,\n",
       "  'grad_norm': 0.025872817263007164,\n",
       "  'learning_rate': 2.2222222222222223e-05,\n",
       "  'epoch': 90.0,\n",
       "  'step': 90},\n",
       " {'eval_loss': 4.229666709899902,\n",
       "  'eval_runtime': 0.3309,\n",
       "  'eval_samples_per_second': 15.111,\n",
       "  'eval_steps_per_second': 6.044,\n",
       "  'epoch': 90.0,\n",
       "  'step': 90},\n",
       " {'loss': 0.0018,\n",
       "  'grad_norm': 0.011597339063882828,\n",
       "  'learning_rate': 2e-05,\n",
       "  'epoch': 91.0,\n",
       "  'step': 91},\n",
       " {'eval_loss': 4.232437610626221,\n",
       "  'eval_runtime': 0.3303,\n",
       "  'eval_samples_per_second': 15.136,\n",
       "  'eval_steps_per_second': 6.055,\n",
       "  'epoch': 91.0,\n",
       "  'step': 91},\n",
       " {'loss': 0.0021,\n",
       "  'grad_norm': 0.020939666777849197,\n",
       "  'learning_rate': 1.777777777777778e-05,\n",
       "  'epoch': 92.0,\n",
       "  'step': 92},\n",
       " {'eval_loss': 4.2319793701171875,\n",
       "  'eval_runtime': 0.3306,\n",
       "  'eval_samples_per_second': 15.123,\n",
       "  'eval_steps_per_second': 6.049,\n",
       "  'epoch': 92.0,\n",
       "  'step': 92},\n",
       " {'loss': 0.0019,\n",
       "  'grad_norm': 0.024129685014486313,\n",
       "  'learning_rate': 1.5555555555555555e-05,\n",
       "  'epoch': 93.0,\n",
       "  'step': 93},\n",
       " {'eval_loss': 4.2319746017456055,\n",
       "  'eval_runtime': 0.3303,\n",
       "  'eval_samples_per_second': 15.136,\n",
       "  'eval_steps_per_second': 6.054,\n",
       "  'epoch': 93.0,\n",
       "  'step': 93},\n",
       " {'loss': 0.002,\n",
       "  'grad_norm': 0.01596885174512863,\n",
       "  'learning_rate': 1.3333333333333333e-05,\n",
       "  'epoch': 94.0,\n",
       "  'step': 94},\n",
       " {'eval_loss': 4.232134819030762,\n",
       "  'eval_runtime': 0.3298,\n",
       "  'eval_samples_per_second': 15.16,\n",
       "  'eval_steps_per_second': 6.064,\n",
       "  'epoch': 94.0,\n",
       "  'step': 94},\n",
       " {'loss': 0.002,\n",
       "  'grad_norm': 0.018632372841238976,\n",
       "  'learning_rate': 1.1111111111111112e-05,\n",
       "  'epoch': 95.0,\n",
       "  'step': 95},\n",
       " {'eval_loss': 4.2312188148498535,\n",
       "  'eval_runtime': 0.3333,\n",
       "  'eval_samples_per_second': 15.003,\n",
       "  'eval_steps_per_second': 6.001,\n",
       "  'epoch': 95.0,\n",
       "  'step': 95},\n",
       " {'loss': 0.0018,\n",
       "  'grad_norm': 0.021278435364365578,\n",
       "  'learning_rate': 8.88888888888889e-06,\n",
       "  'epoch': 96.0,\n",
       "  'step': 96},\n",
       " {'eval_loss': 4.231307029724121,\n",
       "  'eval_runtime': 0.331,\n",
       "  'eval_samples_per_second': 15.104,\n",
       "  'eval_steps_per_second': 6.041,\n",
       "  'epoch': 96.0,\n",
       "  'step': 96},\n",
       " {'loss': 0.002,\n",
       "  'grad_norm': 0.017709940671920776,\n",
       "  'learning_rate': 6.666666666666667e-06,\n",
       "  'epoch': 97.0,\n",
       "  'step': 97},\n",
       " {'eval_loss': 4.232272148132324,\n",
       "  'eval_runtime': 0.3307,\n",
       "  'eval_samples_per_second': 15.119,\n",
       "  'eval_steps_per_second': 6.047,\n",
       "  'epoch': 97.0,\n",
       "  'step': 97},\n",
       " {'loss': 0.0023,\n",
       "  'grad_norm': 0.028060248121619225,\n",
       "  'learning_rate': 4.444444444444445e-06,\n",
       "  'epoch': 98.0,\n",
       "  'step': 98},\n",
       " {'eval_loss': 4.232580661773682,\n",
       "  'eval_runtime': 0.3313,\n",
       "  'eval_samples_per_second': 15.091,\n",
       "  'eval_steps_per_second': 6.036,\n",
       "  'epoch': 98.0,\n",
       "  'step': 98},\n",
       " {'loss': 0.0022,\n",
       "  'grad_norm': 0.026075828820466995,\n",
       "  'learning_rate': 2.2222222222222225e-06,\n",
       "  'epoch': 99.0,\n",
       "  'step': 99},\n",
       " {'eval_loss': 4.233256816864014,\n",
       "  'eval_runtime': 0.3302,\n",
       "  'eval_samples_per_second': 15.145,\n",
       "  'eval_steps_per_second': 6.058,\n",
       "  'epoch': 99.0,\n",
       "  'step': 99},\n",
       " {'loss': 0.0018,\n",
       "  'grad_norm': 0.018686052411794662,\n",
       "  'learning_rate': 0.0,\n",
       "  'epoch': 100.0,\n",
       "  'step': 100},\n",
       " {'eval_loss': 4.233426570892334,\n",
       "  'eval_runtime': 0.3318,\n",
       "  'eval_samples_per_second': 15.068,\n",
       "  'eval_steps_per_second': 6.027,\n",
       "  'epoch': 100.0,\n",
       "  'step': 100},\n",
       " {'train_runtime': 148.7673,\n",
       "  'train_samples_per_second': 10.755,\n",
       "  'train_steps_per_second': 0.672,\n",
       "  'total_flos': 1.264889633891328e+16,\n",
       "  'train_loss': 0.0023713491344824434,\n",
       "  'epoch': 100.0,\n",
       "  'step': 100}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.state.log_history "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_loss)\n",
    "plt.plot(eval_loss)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jmp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
