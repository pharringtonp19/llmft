{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **PyTorch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version: 2.2.2+cu121\n",
      "Cude is available: True\n",
      "Device name: NVIDIA A100-SXM4-40GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "\n",
    "import torch\n",
    "print(f\"Cude is available: {torch.cuda.is_available()}\")\n",
    "print(f\"Device name: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Import Other Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset \n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForCausalLM\n",
    "import numpy as np\n",
    "import evaluate\n",
    "from transformers import TrainingArguments\n",
    "import torch \n",
    "import matplotlib.pyplot as plt \n",
    "from transformers import DataCollatorWithPadding\n",
    "import os \n",
    "from pathlib import Path\n",
    "import random \n",
    "from datasets import Dataset, DatasetDict\n",
    "import warnings\n",
    "from functools import partial\n",
    "from datasets import concatenate_datasets\n",
    "from functools import partial \n",
    "from tqdm import tqdm \n",
    "import textwrap\n",
    "from IPython.display import display\n",
    "from IPython.display import Markdown\n",
    "from trl import SFTTrainer, DataCollatorForCompletionOnlyLM\n",
    "from peft import LoraConfig, get_peft_model \n",
    "from transformers import BitsAndBytesConfig\n",
    "import os \n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "warnings.filterwarnings('ignore', message='Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# This cell is tagged with `parameters`\n",
    "model_name = \"google/gemma-1.1-7b-it\" #microsoft/phi-2\" #\"microsoft/phi-2\" #\"#\"meta-llama/Llama-2-7b-chat-hf\" # \"distilbert-base-uncased\" \n",
    "column = 'text_with_prompt'\n",
    "epochs = 1\n",
    "seed = 0\n",
    "verbose = False \n",
    "test_size = 0.5\n",
    "p = 0.0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Set Up Path**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/llmft/results/\n"
     ]
    }
   ],
   "source": [
    "results_folder = str(Path(os.getcwd()).parent.parent.absolute())  + '/results/'\n",
    "figures_folder = str(Path(os.getcwd()).parent.parent.absolute())  + '/figures/'\n",
    "print(results_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current memory usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n"
     ]
    }
   ],
   "source": [
    "metric = evaluate.load(\"accuracy\")\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "### ---         Memory Check\n",
    "def Memory():\n",
    "    print(\"Current memory usage:\")\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')\n",
    "### ---\n",
    "\n",
    "Memory()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Qlora**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float16\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, get_peft_model \n",
    "from transformers import BitsAndBytesConfig\n",
    "\n",
    "# Activate 4-bit precision base model loading\n",
    "use_4bit = True\n",
    "\n",
    "# Compute dtype for 4-bit base models\n",
    "bnb_4bit_compute_dtype = \"float16\"\n",
    "\n",
    "# Quantization type (fp4 or nf4)\n",
    "bnb_4bit_quant_type = \"nf4\"\n",
    "\n",
    "# Activate nested quantization for 4-bit base models (double quantization)\n",
    "use_nested_quant = True\n",
    "\n",
    "# Load tokenizer and model with QLoRA configuration\n",
    "compute_dtype = getattr(torch, bnb_4bit_compute_dtype)\n",
    "\n",
    "# Enable fp16/bf16 training (set bf16 to True with an A100)\n",
    "fp16 = False\n",
    "bf16 = False\n",
    "\n",
    "# Load tokenizer and model with QLoRA configuration\n",
    "compute_dtype = getattr(torch, bnb_4bit_compute_dtype)\n",
    "print(compute_dtype)\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=use_4bit,\n",
    "    bnb_4bit_quant_type=bnb_4bit_quant_type,\n",
    "    bnb_4bit_compute_dtype=compute_dtype,\n",
    "    bnb_4bit_use_double_quant=use_nested_quant,\n",
    ")\n",
    "\n",
    "# Check GPU compatibility with bfloat16\n",
    "if compute_dtype == torch.float16 and use_4bit:\n",
    "    major, _ = torch.cuda.get_device_capability()\n",
    "    if major >= 8:\n",
    "        print(\"=\" * 80)\n",
    "        print(\"Your GPU supports bfloat16: accelerate training with bf16=True\")\n",
    "        print(\"=\" * 80)\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    r=32,\n",
    "    lora_alpha=64,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    target_modules= [\"Wqkv\", \"out_proj\", \"fc1\", \"fc2\" ] # [\"Wqkv\", \"out_proj\", \"fc1\", \"fc2\" ], - 41M params\n",
    "    # modules_to_save=[\"embed_tokens\",\"lm_head\"] \n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Instantiate Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb175217830a4b65b86a2c9bf5f4ab9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GenerationConfig {\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"eos_token_id\": 50256\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(model_name, \n",
    "                                             device_map=\"auto\", \n",
    "                                             quantization_config=bnb_config, \n",
    "                                             trust_remote_code=True)# So we can do gradient checkpointing\n",
    "print(model.generation_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 26,214,400 || all params: 2,805,898,240 || trainable%: 0.9342605382581515\n",
      "None\n",
      "Current memory usage:\n",
      "Allocated: 0.3 GB\n",
      "Cached:    0.3 GB\n"
     ]
    }
   ],
   "source": [
    "model.config.use_cache = False\n",
    "model.config.pretraining_tp = 1\n",
    "model.config.gradient_checkpointing = False\n",
    "\n",
    "\n",
    "model = get_peft_model(model, peft_config)\n",
    "print(model.print_trainable_parameters())\n",
    "Memory()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Instantiate Tokenizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id \n",
    "tokenizer.padding_side=\"right\"\n",
    "model.config.pad_token_id = tokenizer.eos_token_id # ****I DON'T KNOW WHY WE NEED THIS??***\n",
    "\n",
    "\n",
    "\n",
    "def formatting_prompts_func(example):\n",
    "    # Create a list to store the formatted texts for each item in the example\n",
    "    formatted_texts = []\n",
    "\n",
    "    # Iterate through each example in the batch\n",
    "    for text, raw_label in zip(example[column], example['raw_label']):\n",
    "        # Format each example as a prompt-response pair\n",
    "        formatted_text = f\"{text} {raw_label}\"\n",
    "        formatted_texts.append(formatted_text)\n",
    "\n",
    "    # Return the list of formatted texts\n",
    "    return formatted_texts\n",
    "\n",
    "def single_prompt(example):\n",
    "    return f\"{example[column]} {example['raw_label']}\"\n",
    "\n",
    "\n",
    "def formatting_prompts_func_dict(example):\n",
    "    formatted_texts = []\n",
    "    for text, raw_label in zip(example[column], example['raw_label']):\n",
    "        formatted_text = f\"{text} \"\n",
    "        formatted_texts.append(formatted_text)\n",
    "    return {'formatted_texts': formatted_texts}\n",
    "\n",
    "response_template_with_context = \"\\n\\n    Answer:\"  # We added context here: \"\\n\". This is enough for this tokenizer\n",
    "response_template_ids = tokenizer.encode(response_template_with_context, add_special_tokens=False) # Now we have it like in the dataset texts: `[2277, 29937, 4007, 22137, 29901]`\n",
    "data_collator = DataCollatorForCompletionOnlyLM(response_template_ids, tokenizer=tokenizer)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Data set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21536a38cde941c3b2cec727728e19f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/548 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b118cc3040c49b39542ed88c55aa3a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebdc1485f5514ea4a87110ca339549f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/138k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cd42eb15bb441b0aa8a4dc31eb24d90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27ae0801cb4540bb9103a6fe9bc72ce4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/150 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(f\"ppower1/synthetic_evict_{p}\", split='train', download_mode=\"force_redownload\")\n",
    "\n",
    "\n",
    "# Reshuffle and split the combined dataset with a fixed seed\n",
    "new_splits = dataset.train_test_split(test_size=test_size, seed=seed)  # adjust test_size as needed\n",
    "\n",
    "# Create a new DatasetDict with the shuffled splits\n",
    "reshuffled_dataset = DatasetDict({\n",
    "    'train': new_splits['train'],\n",
    "    'test': new_splits['test']\n",
    "})\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if verbose:\n",
    "    init_results = []\n",
    "    for i in range(150):\n",
    "        input_text = dataset[column][i]\n",
    "        model_inputs = tokenizer(input_text, return_tensors='pt').to('cuda')\n",
    "        greedy_output = model.generate(**model_inputs, max_new_tokens=2)\n",
    "        output_text= tokenizer.decode(greedy_output[0], skip_special_tokens=True)\n",
    "        prediction =  find_first_yes_or_no(output_text[len(input_text):])\n",
    "        target =  dataset['raw_label'][i]\n",
    "        status = prediction == target\n",
    "        if not status:\n",
    "            init_results.append(i)\n",
    "        print(f\" Iter: {i}  | Status: {status}  |   Prediction: {find_first_yes_or_no(output_text[len(input_text):])}   |   Target: {dataset['raw_label'][i]}\")\n",
    "    print(len(init_results)/150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_args(num_epochs):\n",
    "    return TrainingArguments(\n",
    "    output_dir='./synth_evict',\n",
    "    learning_rate=2e-4,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=num_epochs,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    logging_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    gradient_checkpointing=False,\n",
    "    gradient_accumulation_steps=4, \n",
    "    lr_scheduler_type='cosine', # NEW \n",
    "    warmup_ratio = 0.1 # NEW \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "/home/pharrington19/.pyenv/versions/3.10.0/envs/jmp_env/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:194: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff6d2f623c61471e850d00c3d4248bf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/75 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b165c92dedce47f3a897d48d676afce3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/75 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a CodeGenTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19/19 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mppower1\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47ed5b6d57e04f0b84d267884776561e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011113289888887974, max=1.0â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/pharrington19/Documents/GitHub/gpu/evictions/notebooks/huggingface/experiment1/wandb/run-20240220_104300-9n7mfj31</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ppower1/instrumental_llm/runs/9n7mfj31' target=\"_blank\">luminous-orchid-6</a></strong> to <a href='https://wandb.ai/ppower1/instrumental_llm' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ppower1/instrumental_llm' target=\"_blank\">https://wandb.ai/ppower1/instrumental_llm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ppower1/instrumental_llm/runs/9n7mfj31' target=\"_blank\">https://wandb.ai/ppower1/instrumental_llm/runs/9n7mfj31</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Training Loss: 0.9375\n"
     ]
    }
   ],
   "source": [
    "# To get the initial training loss\n",
    "trainer = SFTTrainer(\n",
    "    model,   \n",
    "    args=get_training_args(epochs), \n",
    "    train_dataset=reshuffled_dataset['train'],\n",
    "    eval_dataset=reshuffled_dataset['train'],\n",
    "    formatting_func=formatting_prompts_func,\n",
    "    data_collator=data_collator,\n",
    "    )\n",
    "\n",
    "init_train_eval = trainer.evaluate()\n",
    "init_train_loss = init_train_eval['eval_loss']\n",
    "print(f\"Initial Training Loss: {init_train_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainerCallback\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LLMSampleCB(TrainerCallback):\n",
    "    def __init__(self, trainer, test_dataset, num_samples=10):\n",
    "        super().__init__()\n",
    "        self.sample_dataset = test_dataset.select(range(num_samples))\n",
    "        self.model, self.tokenizer = trainer.model, trainer.tokenizer\n",
    "    \n",
    "    def on_epoch_end(self, args, state, control, **kwargs):\n",
    "        print(\"\\nModel outputs at epoch end:\\n\")\n",
    "        init_results = []\n",
    "        for i in range(len(self.sample_dataset)):\n",
    "            input_text = self.sample_dataset['formatted_texts'][i]\n",
    "            model_inputs = self.tokenizer(input_text, return_tensors='pt').to('cuda')\n",
    "            greedy_output = kwargs['model'].generate(**model_inputs, max_new_tokens=2)\n",
    "            output_text= self.tokenizer.decode(greedy_output[0], skip_special_tokens=True)\n",
    "            prediction =  find_first_yes_or_no(output_text[len(input_text):])\n",
    "            target =  dataset['raw_label'][i]\n",
    "            status = prediction == target\n",
    "            if not status:\n",
    "                init_results.append(i)\n",
    "            print(f\" Iter: {i}  | Status: {status}  |   Prediction: {find_first_yes_or_no(output_text[len(input_text):])}   |   Target: {dataset['raw_label'][i]}\")\n",
    "        print(len(init_results)/150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "/home/pharrington19/.pyenv/versions/3.10.0/envs/jmp_env/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:194: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8d7b3934b1f41d7991fc265c04a7bcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/75 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='20' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19/19 00:15]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Evaluation Loss: 1.0259\n"
     ]
    }
   ],
   "source": [
    "# To get the initial training loss\n",
    "trainer = SFTTrainer(\n",
    "    model,   \n",
    "    args=get_training_args(epochs), \n",
    "    train_dataset=reshuffled_dataset['train'],\n",
    "    eval_dataset=reshuffled_dataset['test'],\n",
    "    formatting_func=formatting_prompts_func,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "init_eval_eval = trainer.evaluate()\n",
    "init_eval_loss = init_eval_eval['eval_loss']\n",
    "print(f\"Initial Evaluation Loss: {init_eval_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60ead0e8def946c3af448c8ed97544a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/75 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a68f881dde848f28249bbcc24d68e3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/75 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_dataset = reshuffled_dataset.map(formatting_prompts_func_dict, batched=True)['test']\n",
    "wandb_callback = LLMSampleCB(trainer, test_dataset, num_samples=10)\n",
    "trainer.add_callback(wandb_callback)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 00:13, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.744400</td>\n",
       "      <td>0.246928</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model outputs at epoch end:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pharrington19/.pyenv/versions/3.10.0/envs/jmp_env/lib/python3.10/site-packages/transformers/generation/utils.py:1518: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Iter: 0  | Status: False  |   Prediction: None   |   Target: No\n",
      " Iter: 1  | Status: False  |   Prediction: None   |   Target: No\n",
      " Iter: 2  | Status: False  |   Prediction: None   |   Target: Yes\n",
      " Iter: 3  | Status: False  |   Prediction: None   |   Target: No\n",
      " Iter: 4  | Status: False  |   Prediction: None   |   Target: No\n",
      " Iter: 5  | Status: False  |   Prediction: None   |   Target: No\n",
      " Iter: 6  | Status: False  |   Prediction: None   |   Target: Yes\n",
      " Iter: 7  | Status: False  |   Prediction: None   |   Target: No\n",
      " Iter: 8  | Status: False  |   Prediction: None   |   Target: No\n",
      " Iter: 9  | Status: False  |   Prediction: None   |   Target: No\n",
      "0.06666666666666667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=4, training_loss=0.7444037199020386, metrics={'train_runtime': 15.2296, 'train_samples_per_second': 4.925, 'train_steps_per_second': 0.263, 'total_flos': 230142049689600.0, 'train_loss': 0.7444037199020386, 'epoch': 0.84})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 0 | Max Prob: 1.0000 | Prob : 0.9989 | Status: True | Prediction: No | Target: No\n",
      "Iter: 1 | Max Prob: 1.0000 | Prob : 1.0000 | Status: True | Prediction: No | Target: No\n",
      "Iter: 2 | Max Prob: 0.5126 | Prob : 0.0018 | Status: True | Prediction: Yes | Target: Yes\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn.functional import softmax\n",
    "\n",
    "# Assuming `model` and `tokenizer` are already defined and configured for CUDA as in your setup\n",
    "\n",
    "init_results = []\n",
    "yes_token_id = tokenizer.encode('Yes', add_special_tokens=False)[0]  # Get token ID for 'Yes'\n",
    "\n",
    "for i in range(150):\n",
    "    input_text = dataset[column][i]\n",
    "    model_inputs = tokenizer(input_text, return_tensors='pt').to('cuda')\n",
    "    \n",
    "    # Directly use the model for inference to get logits\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**model_inputs, labels=model_inputs[\"input_ids\"])\n",
    "        logits = outputs.logits  # Assuming you want the logits for the last token for 'Yes'\n",
    "\n",
    "    \n",
    "    # Calculate log probabilities\n",
    "    output_probs = softmax(logits[0, -1, :], dim=0)  # Log probabilities of the last token\n",
    "    \n",
    "    \n",
    "    # Extract log probability of 'Yes'\n",
    "    output_prob = output_probs[yes_token_id].item()  # Log prob of 'Yes'\n",
    "    \n",
    "    # Your existing logic to determine prediction, status, and whether to add to init_results\n",
    "    greedy_output = model.generate(**model_inputs, max_new_tokens=2)\n",
    "    output_text = tokenizer.decode(greedy_output[0], skip_special_tokens=True)\n",
    "    prediction = find_first_yes_or_no(output_text[len(input_text):])\n",
    "    target = dataset['raw_label'][i]\n",
    "    if target == 'No':\n",
    "        output_prob = 1 - output_prob\n",
    "        value =  1.0 - torch.min(output_probs)\n",
    "    else:\n",
    "        value =  torch.max(output_probs)\n",
    "    status = prediction == target\n",
    "\n",
    "    if not status:\n",
    "        init_results.append((i, output_prob))  # Append index and log prob of 'Yes'\n",
    "    print(f\"Iter: {i} | Max Prob: {value:.4f} | Prob : {output_prob:.4f} | Status: {status} | Prediction: {prediction} | Target: {target}\")\n",
    "    if i > 1 :\n",
    "        break   \n",
    "#print(len(init_results)/150)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0011, device='cuda:3')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_probs[yes_token_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6862, device='cuda:3')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(output_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps, train_loss = [0] + [i['step'] for i in trainer.state.log_history if 'loss' in i], [init_train_loss] + [i['loss'] for i in trainer.state.log_history if 'loss' in i]\n",
    "_, eval_loss = [i['step'] for i in trainer.state.log_history if 'eval_loss' in i], [init_eval_loss] + [i['eval_loss'] for i in trainer.state.log_history if 'eval_loss' in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i['learning_rate'] for i in trainer.state.log_history if 'learning_rate' in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0258930921554565, 0.24692779779434204]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_loss, label='Train')\n",
    "plt.plot(eval_loss, label='Test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(datafolder + f'synth_evict_steps_causalm.npy', np.array(steps))\n",
    "np.save(datafolder + f'synth_evict_pred_train_loss_causalm_phi2_{column}_{seed}_{p}_{test_size}.npy', np.array(train_loss))\n",
    "np.save(datafolder + f'synth_evict_pred_eval_loss_causalm_phi2_{column}_{seed}_{p}_{test_size}.npy', np.array(eval_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jmp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
